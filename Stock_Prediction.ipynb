{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "48543d9c-7dbf-4d5d-bd24-ff33ea869103",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Machine Learning Algorithms used to predict the Stock Market Behaviour with Exogenous variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "725c6cfa-2e0a-4fa9-b7b2-2e48b2094aa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Top 10 Predictions vs Actuals:\n",
      "      Actual_Confidence  Predicted_Confidence Actual_Class Predicted_Class\n",
      "247            0.572501              0.627543      Neutral         Neutral\n",
      "1293           0.639770              0.662385      Neutral         Bullish\n",
      "1562           0.423568              0.486638      Neutral         Neutral\n",
      "1101           0.255415              0.406810      Bearish         Neutral\n",
      "1161           0.635864              0.588450      Neutral         Neutral\n",
      "382            0.457954              0.490487      Neutral         Neutral\n",
      "1197           0.735602              0.722561      Bullish         Bullish\n",
      "777            0.513502              0.498765      Neutral         Neutral\n",
      "643            0.585349              0.589357      Neutral         Neutral\n",
      "275            0.511786              0.540493      Neutral         Neutral\n",
      "\n",
      " Mean Squared Error: 0.00210467949629224\n",
      "\n",
      " Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Bearish       0.67      0.67      0.67         6\n",
      "     Bullish       0.79      0.70      0.74        77\n",
      "     Neutral       0.91      0.94      0.93       283\n",
      "\n",
      "    accuracy                           0.89       366\n",
      "   macro avg       0.79      0.77      0.78       366\n",
      "weighted avg       0.89      0.89      0.89       366\n",
      "\n",
      "\n",
      " Confusion Matrix:\n",
      "[[  4   0   2]\n",
      " [  0  54  23]\n",
      " [  2  14 267]]\n",
      "\n",
      " Overall Accuracy: 88.80%\n"
     ]
    }
   ],
   "source": [
    "# Linear Regression. (Supervised Learning)\n",
    "# Linear Regression is a supervised machine learning algorithm(where machined is trained that a particular inut will give a particular output). \n",
    "# It basically fits a straight line which predicts a dependent term based on the independent term. Ex- Y=mx+c\n",
    "\n",
    "# Prediction of the stock market behaviour using Linear Regression\n",
    "\n",
    "import pandas as pd                                  # pandas are used for data operations\n",
    "from sklearn.model_selection import train_test_split # it is used to split the data (some for training and some for testing)\n",
    "from sklearn.linear_model import LinearRegression    # used to fit a LinearRegression model\n",
    "from sklearn.preprocessing import StandardScaler     # used to rescale all the features used as no high value feature dominates low value feature.\n",
    "                                                     # a particular value of the feature is subtracted by mean and divided by the variance\n",
    "from sklearn.metrics import mean_squared_error, classification_report, confusion_matrix, accuracy_score\n",
    "                                                     # it is used to obtain the observed results\n",
    "from collections import Counter                      # it is used to count the occurance af a particular element\n",
    "\n",
    "# Loading the dataset\n",
    "df = pd.read_csv(\"C:/Users/luvkh/data/Datasets/stock_data_with_exogenous_variables.csv\")\n",
    "\n",
    "# Clean column names(remove all the characters that are not letter, number or underscore)\n",
    "df.columns = df.columns.str.replace(r'[^\\w]', '_', regex=True)\n",
    "\n",
    "# These columns are used to obtain Market_Confidence hence noting it down to drop these from the training data\n",
    "formula_columns = [\n",
    "    'Price_Change', 'StockMarket_Trend', 'Sentiment',\n",
    "    'ATR', 'Stochastic', 'Momentum', 'IsFedMeetingDay', 'CoreCPI'\n",
    "]\n",
    "\n",
    "# Defining the target column\n",
    "y = df['Market_Confidence']\n",
    "\n",
    "# Defining the training column\n",
    "X = df.drop(columns=formula_columns + ['Market_Confidence'])\n",
    "\n",
    "# Selecting only numeric features (Not including Dates, Top1 - Top25, All news)\n",
    "X = X.select_dtypes(include='number')\n",
    "\n",
    "# Split into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(       # 80% data is been trained and 20% of the data is been tested\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Scaling of the Training data and testing data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Fitting a Linear Regression model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predict confidence\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "# Class assigning based upon the Market_Confidence (Bullish/Bearish/Neutral)\n",
    "def confidence_to_class(conf):\n",
    "    if conf < 0.33:\n",
    "        return \"Bearish\"\n",
    "    elif conf <= 0.66:\n",
    "        return \"Neutral\"\n",
    "    else:\n",
    "        return \"Bullish\"\n",
    "\n",
    "y_test_class = [confidence_to_class(val) for val in y_test]        # Actual class of the Market_Confidence\n",
    "y_pred_class = [confidence_to_class(val) for val in y_pred]        # Predicted class of the Market_Confidence\n",
    "\n",
    "# Creating a DataFrame consisting of 4 columns\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Actual_Confidence': y_test,\n",
    "    'Predicted_Confidence': y_pred,\n",
    "    'Actual_Class': y_test_class,\n",
    "    'Predicted_Class': y_pred_class\n",
    "})\n",
    "print(\"\\n Top 10 Predictions vs Actuals:\")\n",
    "print(comparison_df.head(10))                                      # out of the 20% tested data, it shows the top 10\n",
    "\n",
    "# Evaluation\n",
    "\n",
    "# Mean square method is used to obtain how far our model predicted from the actual values.\n",
    "# It is calculating by subtracting predicted values with actual values(error) then square it and take average.\n",
    "print(\"\\n Mean Squared Error:\", mean_squared_error(y_test, y_pred))\n",
    "\n",
    "# Classification report gives detail about how well the model handled each class\n",
    "print(\"\\n Classification Report:\")\n",
    "print(classification_report(y_test_class, y_pred_class))\n",
    "\n",
    "# A table which gives actual(rows) vs predicted(columns) value\n",
    "print(\"\\n Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test_class, y_pred_class))\n",
    "\n",
    "# Print accuracy score\n",
    "accuracy = accuracy_score(y_test_class, y_pred_class)\n",
    "print(f\"\\n Overall Accuracy: {accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab8f7975-c6cd-42c2-ab90-8f8d5643989f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Top 10 Predictions vs Actuals:\n",
      "      Actual_Confidence  Predicted_Confidence Actual_Class Predicted_Class\n",
      "247            0.572501              0.616329      Neutral         Neutral\n",
      "1293           0.639770              0.668870      Neutral         Bullish\n",
      "1562           0.423568              0.504211      Neutral         Neutral\n",
      "1101           0.255415              0.435123      Bearish         Neutral\n",
      "1161           0.635864              0.600252      Neutral         Neutral\n",
      "382            0.457954              0.503097      Neutral         Neutral\n",
      "1197           0.735602              0.697902      Bullish         Bullish\n",
      "777            0.513502              0.506101      Neutral         Neutral\n",
      "643            0.585349              0.591749      Neutral         Neutral\n",
      "275            0.511786              0.542211      Neutral         Neutral\n",
      "\n",
      " Mean Squared Error: 0.0022548728917693474\n",
      "\n",
      " Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Bearish       1.00      0.67      0.80         6\n",
      "     Bullish       0.79      0.70      0.74        77\n",
      "     Neutral       0.91      0.95      0.93       283\n",
      "\n",
      "    accuracy                           0.89       366\n",
      "   macro avg       0.90      0.77      0.83       366\n",
      "weighted avg       0.89      0.89      0.89       366\n",
      "\n",
      "\n",
      " Confusion Matrix:\n",
      "[[  4   0   2]\n",
      " [  0  54  23]\n",
      " [  0  14 269]]\n",
      "\n",
      " Overall Accuracy: 89.34%\n"
     ]
    }
   ],
   "source": [
    "# Ridge Regression. (Supervised Learning)\n",
    "# Ridge Regression is the smart version of the Linear Regressino. Sometimes Linear Regression gives more weights to some features. Ridge Regression keeps\n",
    "# the weight small and balanced. Y = w1x1 + w2x2 +.........+ wnxn where w1,w2....wn are the weights\n",
    "\n",
    "# Prediction of the stock market behaviour using Ridge Regression\n",
    "\n",
    "import pandas as pd                                  # pandas are used for data operations\n",
    "from sklearn.model_selection import train_test_split # it is used to split the data (some for training and some for testing)\n",
    "from sklearn.linear_model import Ridge               # used to fit a Ridge Regression model\n",
    "from sklearn.preprocessing import StandardScaler     # used to rescale all the features used as no high value feature dominates low value feature.\n",
    "                                                     # a particular value of the feature is subtracted by mean and divided by the variance\n",
    "from sklearn.metrics import mean_squared_error, classification_report, confusion_matrix, accuracy_score\n",
    "                                                     # it is used to obtain the observed results\n",
    "from collections import Counter                      # it is used to count the occurance of a particular element\n",
    "\n",
    "# Loading the dataset\n",
    "df = pd.read_csv(\"C:/Users/luvkh/data/Datasets/stock_data_with_exogenous_variables.csv\")\n",
    "\n",
    "# Clean column names(remove all the characters that are not letter, number or underscore)\n",
    "df.columns = df.columns.str.replace(r'[^\\w]', '_', regex=True)\n",
    "\n",
    "# These columns are used to obtain Market_Confidence hence noting it down to drop these from the training data\n",
    "formula_columns = [\n",
    "    'Price_Change', 'StockMarket_Trend', 'Sentiment',\n",
    "    'ATR', 'Stochastic', 'Momentum', 'IsFedMeetingDay', 'CoreCPI'\n",
    "]\n",
    "\n",
    "# Defining the target column\n",
    "y = df['Market_Confidence']\n",
    "\n",
    "# Defining the training column\n",
    "X = df.drop(columns=formula_columns + ['Market_Confidence'])\n",
    "\n",
    "# Selecting only numeric features (Not including Dates, Top1 - Top25, All news)\n",
    "X = X.select_dtypes(include='number')\n",
    "\n",
    "# Split into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(       # 80% data is been trained and 20% of the data is been tested\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Scaling of the Training data and testing data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Fitting a Ridge Regression model\n",
    "model = Ridge(alpha=1.0)    # higher the alpha value lower and appropriate is the weight. lower the alpha value more it behaves like linear regression\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predict confidence\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "# Class assigning based upon the Market_Confidence (Bullish/Bearish/Neutral)\n",
    "def confidence_to_class(conf):\n",
    "    if conf < 0.33:\n",
    "        return \"Bearish\"\n",
    "    elif conf <= 0.66:\n",
    "        return \"Neutral\"\n",
    "    else:\n",
    "        return \"Bullish\"\n",
    "\n",
    "y_test_class = [confidence_to_class(val) for val in y_test]        # Actual class of the Market_Confidence\n",
    "y_pred_class = [confidence_to_class(val) for val in y_pred]        # Predicted class of the Market_Confidence\n",
    "\n",
    "# Creating a DataFrame consisting of 4 columns\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Actual_Confidence': y_test,\n",
    "    'Predicted_Confidence': y_pred,\n",
    "    'Actual_Class': y_test_class,\n",
    "    'Predicted_Class': y_pred_class\n",
    "})\n",
    "print(\"\\n Top 10 Predictions vs Actuals:\")\n",
    "print(comparison_df.head(10))                                      # out of the 20% tested data, it shows the top 10\n",
    "\n",
    "# Evaluation\n",
    "\n",
    "# Mean square method is used to obtain how far our model predicted from the actual values.\n",
    "# It is calculating by subtracting predicted values with actual values(error) then square it and take average.\n",
    "print(\"\\n Mean Squared Error:\", mean_squared_error(y_test, y_pred))\n",
    "\n",
    "# Classification report gives detail about how well the model handled each class\n",
    "print(\"\\n Classification Report:\")\n",
    "print(classification_report(y_test_class, y_pred_class))\n",
    "\n",
    "# A table which gives actual(rows) vs predicted(columns) value\n",
    "print(\"\\n Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test_class, y_pred_class))\n",
    "\n",
    "# Print accuracy score\n",
    "accuracy = accuracy_score(y_test_class, y_pred_class)\n",
    "print(f\"\\n Overall Accuracy: {accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "266acd80-5dbc-48de-b6bd-52572eacce9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Top 10 Predictions vs Actuals:\n",
      "      Actual_Confidence  Predicted_Confidence Actual_Class Predicted_Class\n",
      "247            0.572501              0.575428      Neutral         Neutral\n",
      "1293           0.639770              0.656835      Neutral         Neutral\n",
      "1562           0.423568              0.606721      Neutral         Neutral\n",
      "1101           0.255415              0.592229      Bearish         Neutral\n",
      "1161           0.635864              0.650599      Neutral         Neutral\n",
      "382            0.457954              0.555656      Neutral         Neutral\n",
      "1197           0.735602              0.595077      Bullish         Neutral\n",
      "777            0.513502              0.536533      Neutral         Neutral\n",
      "643            0.585349              0.605111      Neutral         Neutral\n",
      "275            0.511786              0.556848      Neutral         Neutral\n",
      "\n",
      " Mean Squared Error: 0.006538738689870886\n",
      "\n",
      " Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Bearish       1.00      0.50      0.67         6\n",
      "     Bullish       0.79      0.14      0.24        77\n",
      "     Neutral       0.80      0.99      0.89       283\n",
      "\n",
      "    accuracy                           0.80       366\n",
      "   macro avg       0.86      0.54      0.60       366\n",
      "weighted avg       0.80      0.80      0.75       366\n",
      "\n",
      "\n",
      " Confusion Matrix:\n",
      "[[  3   0   3]\n",
      " [  0  11  66]\n",
      " [  0   3 280]]\n",
      "\n",
      " Overall Accuracy: 80.33%\n"
     ]
    }
   ],
   "source": [
    "# Lasso Regression. (Supervised Learning)\n",
    "# Lasso Regression is a linear regression with some of the less importnat feaures are been removed.\n",
    "# Y = w1x1 + w2x2 +.........+ wnxn where w1,w2....wn are the weights with some of the weights as 0 which is less important. \n",
    "\n",
    "# Prediction of the stock market behaviour using Lasso Regression\n",
    "\n",
    "import pandas as pd                                  # pandas are used for data operations\n",
    "from sklearn.model_selection import train_test_split # it is used to split the data (some for training and some for testing)\n",
    "from sklearn.linear_model import Lasso               # used to fit a Lasso Regression model\n",
    "from sklearn.preprocessing import StandardScaler     # used to rescale all the features used as no high value feature dominates low value feature.\n",
    "                                                     # a particular value of the feature is subtracted by mean and divided by the variance\n",
    "from sklearn.metrics import mean_squared_error, classification_report, confusion_matrix, accuracy_score\n",
    "                                                     # it is used to obtain the observed results\n",
    "from collections import Counter                      # it is used to count the occurance of a particular element\n",
    "\n",
    "# Loading the dataset\n",
    "df = pd.read_csv(\"C:/Users/luvkh/data/Datasets/stock_data_with_exogenous_variables.csv\")\n",
    "\n",
    "# Clean column names(remove all the characters that are not letter, number or underscore)\n",
    "df.columns = df.columns.str.replace(r'[^\\w]', '_', regex=True)\n",
    "\n",
    "# These columns are used to obtain Market_Confidence hence noting it down to drop these from the training data\n",
    "formula_columns = [\n",
    "    'Price_Change', 'StockMarket_Trend', 'Sentiment',\n",
    "    'ATR', 'Stochastic', 'Momentum', 'IsFedMeetingDay', 'CoreCPI'\n",
    "]\n",
    "\n",
    "# Defining the target column\n",
    "y = df['Market_Confidence']\n",
    "\n",
    "# Defining the training column\n",
    "X = df.drop(columns=formula_columns + ['Market_Confidence'])\n",
    "\n",
    "# Selecting only numeric features (Not including Dates, Top1 - Top25, All news)\n",
    "X = X.select_dtypes(include='number')\n",
    "\n",
    "# Split into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(       # 80% data is been trained and 20% of the data is been tested\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Scaling of the Training data and testing data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Fitting a Lasso Regression model\n",
    "model = Lasso(alpha=0.01) # larger the alpha value stronger is the module as unwanted feaures are removed by making unwanted weights 0.\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predict confidence\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "# Class assigning based upon the Market_Confidence (Bullish/Bearish/Neutral)\n",
    "def confidence_to_class(conf):\n",
    "    if conf < 0.33:\n",
    "        return \"Bearish\"\n",
    "    elif conf <= 0.66:\n",
    "        return \"Neutral\"\n",
    "    else:\n",
    "        return \"Bullish\"\n",
    "\n",
    "y_test_class = [confidence_to_class(val) for val in y_test]        # Actual class of the Market_Confidence\n",
    "y_pred_class = [confidence_to_class(val) for val in y_pred]        # Predicted class of the Market_Confidence\n",
    "\n",
    "# Creating a DataFrame consisting of 4 columns\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Actual_Confidence': y_test,\n",
    "    'Predicted_Confidence': y_pred,\n",
    "    'Actual_Class': y_test_class,\n",
    "    'Predicted_Class': y_pred_class\n",
    "})\n",
    "print(\"\\n Top 10 Predictions vs Actuals:\")\n",
    "print(comparison_df.head(10))                                      # out of the 20% tested data, it shows the top 10\n",
    "\n",
    "# Evaluation\n",
    "\n",
    "# Mean square method is used to obtain how far our model predicted from the actual values.\n",
    "# It is calculating by subtracting predicted values with actual values(error) then square it and take average.\n",
    "print(\"\\n Mean Squared Error:\", mean_squared_error(y_test, y_pred))\n",
    "\n",
    "# Classification report gives detail about how well the model handled each class\n",
    "print(\"\\n Classification Report:\")\n",
    "print(classification_report(y_test_class, y_pred_class))\n",
    "\n",
    "# A table which gives actual(rows) vs predicted(columns) value\n",
    "print(\"\\n Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test_class, y_pred_class))\n",
    "\n",
    "# Print accuracy score\n",
    "accuracy = accuracy_score(y_test_class, y_pred_class)\n",
    "print(f\"\\n Overall Accuracy: {accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "95a52ca0-4b5b-4556-9981-1ff311ed08be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Top 10 Predictions vs Actuals:\n",
      "      Actual_Confidence  Predicted_Confidence Actual_Class Predicted_Class\n",
      "247            0.572501              0.646743      Neutral         Neutral\n",
      "1293           0.639770              0.640439      Neutral         Neutral\n",
      "1562           0.423568              0.593609      Neutral         Neutral\n",
      "1101           0.255415              0.593609      Bearish         Neutral\n",
      "1161           0.635864              0.640439      Neutral         Neutral\n",
      "382            0.457954              0.582426      Neutral         Neutral\n",
      "1197           0.735602              0.795242      Bullish         Bullish\n",
      "777            0.513502              0.435019      Neutral         Neutral\n",
      "643            0.585349              0.593609      Neutral         Neutral\n",
      "275            0.511786              0.570874      Neutral         Neutral\n",
      "\n",
      " Mean Squared Error: 0.007307169285807634\n",
      "\n",
      " Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Bearish       1.00      0.67      0.80         6\n",
      "     Bullish       0.89      0.10      0.19        77\n",
      "     Neutral       0.80      1.00      0.89       283\n",
      "\n",
      "    accuracy                           0.80       366\n",
      "   macro avg       0.90      0.59      0.62       366\n",
      "weighted avg       0.82      0.80      0.74       366\n",
      "\n",
      "\n",
      " Confusion Matrix:\n",
      "[[  4   0   2]\n",
      " [  0   8  69]\n",
      " [  0   1 282]]\n",
      "\n",
      " Overall Accuracy: 80.33%\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree Regression. (Supervised Algorithm)\n",
    "# Decision Tree Regression is a non-linear machine learning algorithm. Instead of fitting a straight line, it splits the data in the yes no form like\n",
    "# flowchart.\n",
    "# Prediction of the stock market behaviour using Decision Tree Regression\n",
    "\n",
    "import pandas as pd                                  # pandas are used for data operations\n",
    "from sklearn.model_selection import train_test_split # it is used to split the data (some for training and some for testing)\n",
    "from sklearn.tree import DecisionTreeRegressor       # used to fit a Decision Tree Regressor model\n",
    "from sklearn.preprocessing import StandardScaler     # used to rescale all the features used as no high value feature dominates low value feature.\n",
    "                                                     # a particular value of the feature is subtracted by mean and divided by the variance\n",
    "from sklearn.metrics import mean_squared_error, classification_report, confusion_matrix, accuracy_score\n",
    "                                                     # it is used to obtain the observed results\n",
    "from collections import Counter                      # it is used to count the occurance of a particular element\n",
    "\n",
    "# Loading the dataset\n",
    "df = pd.read_csv(\"C:/Users/luvkh/data/Datasets/stock_data_with_exogenous_variables.csv\")\n",
    "\n",
    "# Clean column names(remove all the characters that are not letter, number or underscore)\n",
    "df.columns = df.columns.str.replace(r'[^\\w]', '_', regex=True)\n",
    "\n",
    "# These columns are used to obtain Market_Confidence hence noting it down to drop these from the training data\n",
    "formula_columns = [\n",
    "    'Price_Change', 'StockMarket_Trend', 'Sentiment',\n",
    "    'ATR', 'Stochastic', 'Momentum', 'IsFedMeetingDay', 'CoreCPI'\n",
    "]\n",
    "\n",
    "# Defining the target column\n",
    "y = df['Market_Confidence']\n",
    "\n",
    "# Defining the training column\n",
    "X = df.drop(columns=formula_columns + ['Market_Confidence'])\n",
    "\n",
    "# Selecting only numeric features (Not including Dates, Top1 - Top25, All news)\n",
    "X = X.select_dtypes(include='number')\n",
    "\n",
    "# Split into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(       # 80% data is been trained and 20% of the data is been tested\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Scaling of the Training data and testing data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Fitting a Decision Tree Regression model\n",
    "model = DecisionTreeRegressor(max_depth=5, random_state=42)   # 5 roots \n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predict confidence\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "# Class assigning based upon the Market_Confidence (Bullish/Bearish/Neutral)\n",
    "def confidence_to_class(conf):\n",
    "    if conf < 0.33:\n",
    "        return \"Bearish\"\n",
    "    elif conf <= 0.66:\n",
    "        return \"Neutral\"\n",
    "    else:\n",
    "        return \"Bullish\"\n",
    "\n",
    "y_test_class = [confidence_to_class(val) for val in y_test]        # Actual class of the Market_Confidence\n",
    "y_pred_class = [confidence_to_class(val) for val in y_pred]        # Predicted class of the Market_Confidence\n",
    "\n",
    "# Creating a DataFrame consisting of 4 columns\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Actual_Confidence': y_test,\n",
    "    'Predicted_Confidence': y_pred,\n",
    "    'Actual_Class': y_test_class,\n",
    "    'Predicted_Class': y_pred_class\n",
    "})\n",
    "print(\"\\n Top 10 Predictions vs Actuals:\")\n",
    "print(comparison_df.head(10))                                      # out of the 20% tested data, it shows the top 10\n",
    "\n",
    "# Evaluation\n",
    "\n",
    "# Mean square method is used to obtain how far our model predicted from the actual values.\n",
    "# It is calculating by subtracting predicted values with actual values(error) then square it and take average.\n",
    "print(\"\\n Mean Squared Error:\", mean_squared_error(y_test, y_pred))\n",
    "\n",
    "# Classification report gives detail about how well the model handled each class\n",
    "print(\"\\n Classification Report:\")\n",
    "print(classification_report(y_test_class, y_pred_class))\n",
    "\n",
    "# A table which gives actual(rows) vs predicted(columns) value\n",
    "print(\"\\n Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test_class, y_pred_class))\n",
    "\n",
    "# Print accuracy score\n",
    "accuracy = accuracy_score(y_test_class, y_pred_class)\n",
    "print(f\"\\n Overall Accuracy: {accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1c14be67-c477-44d8-86f8-ce33e2ce1732",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Top 10 Predictions vs Actuals:\n",
      "      Actual_Confidence  Predicted_Confidence Actual_Class Predicted_Class\n",
      "247            0.572501              0.592317      Neutral         Neutral\n",
      "1293           0.639770              0.666071      Neutral         Bullish\n",
      "1562           0.423568              0.580331      Neutral         Neutral\n",
      "1101           0.255415              0.556146      Bearish         Neutral\n",
      "1161           0.635864              0.649530      Neutral         Neutral\n",
      "382            0.457954              0.527018      Neutral         Neutral\n",
      "1197           0.735602              0.585333      Bullish         Neutral\n",
      "777            0.513502              0.532431      Neutral         Neutral\n",
      "643            0.585349              0.612472      Neutral         Neutral\n",
      "275            0.511786              0.540570      Neutral         Neutral\n",
      "\n",
      " Mean Squared Error: 0.004570971017688775\n",
      "\n",
      " Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Bearish       1.00      0.67      0.80         6\n",
      "     Bullish       0.70      0.48      0.57        77\n",
      "     Neutral       0.86      0.94      0.90       283\n",
      "\n",
      "    accuracy                           0.84       366\n",
      "   macro avg       0.85      0.70      0.76       366\n",
      "weighted avg       0.83      0.84      0.83       366\n",
      "\n",
      "\n",
      " Confusion Matrix:\n",
      "[[  4   0   2]\n",
      " [  0  37  40]\n",
      " [  0  16 267]]\n",
      "\n",
      " Overall Accuracy: 84.15%\n"
     ]
    }
   ],
   "source": [
    "# Random Forest Regression. (Supervised Algorithm)\n",
    "# Random Forest Regressor takes multiple Decision Trees and take average of the predictions.\n",
    "\n",
    "# Prediction of the stock market behaviour using Random Forest Regression\n",
    "\n",
    "import pandas as pd                                  # pandas are used for data operations\n",
    "from sklearn.model_selection import train_test_split # it is used to split the data (some for training and some for testing)\n",
    "from sklearn.ensemble import RandomForestRegressor   # used to fit a Random Forest Regressor model\n",
    "from sklearn.preprocessing import StandardScaler     # used to rescale all the features used as no high value feature dominates low value feature.\n",
    "                                                     # a particular value of the feature is subtracted by mean and divided by the variance\n",
    "from sklearn.metrics import mean_squared_error, classification_report, confusion_matrix, accuracy_score\n",
    "                                                     # it is used to obtain the observed results\n",
    "from collections import Counter                      # it is used to count the occurance of a particular element\n",
    "\n",
    "# Loading the dataset\n",
    "df = pd.read_csv(\"C:/Users/luvkh/data/Datasets/stock_data_with_exogenous_variables.csv\")\n",
    "\n",
    "# Clean column names(remove all the characters that are not letter, number or underscore)\n",
    "df.columns = df.columns.str.replace(r'[^\\w]', '_', regex=True)\n",
    "\n",
    "# These columns are used to obtain Market_Confidence hence noting it down to drop these from the training data\n",
    "formula_columns = [\n",
    "    'Price_Change', 'StockMarket_Trend', 'Sentiment',\n",
    "    'ATR', 'Stochastic', 'Momentum', 'IsFedMeetingDay', 'CoreCPI'\n",
    "]\n",
    "\n",
    "# Defining the target column\n",
    "y = df['Market_Confidence']\n",
    "\n",
    "# Defining the training column\n",
    "X = df.drop(columns=formula_columns + ['Market_Confidence'])\n",
    "\n",
    "# Selecting only numeric features (Not including Dates, Top1 - Top25, All news)\n",
    "X = X.select_dtypes(include='number')\n",
    "\n",
    "# Split into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(       # 80% data is been trained and 20% of the data is been tested\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Scaling of the Training data and testing data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Fitting a Random Forest Regression model\n",
    "model = RandomForestRegressor(n_estimators=100, random_state=42)   # 100 trees are been taken into consideration\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predict confidence\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "# Class assigning based upon the Market_Confidence (Bullish/Bearish/Neutral)\n",
    "def confidence_to_class(conf):\n",
    "    if conf < 0.33:\n",
    "        return \"Bearish\"\n",
    "    elif conf <= 0.66:\n",
    "        return \"Neutral\"\n",
    "    else:\n",
    "        return \"Bullish\"\n",
    "\n",
    "y_test_class = [confidence_to_class(val) for val in y_test]        # Actual class of the Market_Confidence\n",
    "y_pred_class = [confidence_to_class(val) for val in y_pred]        # Predicted class of the Market_Confidence\n",
    "\n",
    "# Creating a DataFrame consisting of 4 columns\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Actual_Confidence': y_test,\n",
    "    'Predicted_Confidence': y_pred,\n",
    "    'Actual_Class': y_test_class,\n",
    "    'Predicted_Class': y_pred_class\n",
    "})\n",
    "print(\"\\n Top 10 Predictions vs Actuals:\")\n",
    "print(comparison_df.head(10))                                      # out of the 20% tested data, it shows the top 10\n",
    "\n",
    "# Evaluation\n",
    "\n",
    "# Mean square method is used to obtain how far our model predicted from the actual values.\n",
    "# It is calculating by subtracting predicted values with actual values(error) then square it and take average.\n",
    "print(\"\\n Mean Squared Error:\", mean_squared_error(y_test, y_pred))\n",
    "\n",
    "# Classification report gives detail about how well the model handled each class\n",
    "print(\"\\n Classification Report:\")\n",
    "print(classification_report(y_test_class, y_pred_class))\n",
    "\n",
    "# A table which gives actual(rows) vs predicted(columns) value\n",
    "print(\"\\n Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test_class, y_pred_class))\n",
    "\n",
    "# Print accuracy score\n",
    "accuracy = accuracy_score(y_test_class, y_pred_class)\n",
    "print(f\"\\n Overall Accuracy: {accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8766ed88-bb45-430d-987a-d839a8b1c2af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Top 10 Predictions vs Actuals:\n",
      "      Actual_Confidence  Predicted_Confidence Actual_Class Predicted_Class\n",
      "247            0.572501              0.576908      Neutral         Neutral\n",
      "1293           0.639770              0.652724      Neutral         Neutral\n",
      "1562           0.423568              0.577411      Neutral         Neutral\n",
      "1101           0.255415              0.445630      Bearish         Neutral\n",
      "1161           0.635864              0.616019      Neutral         Neutral\n",
      "382            0.457954              0.518533      Neutral         Neutral\n",
      "1197           0.735602              0.582962      Bullish         Neutral\n",
      "777            0.513502              0.552472      Neutral         Neutral\n",
      "643            0.585349              0.597301      Neutral         Neutral\n",
      "275            0.511786              0.533722      Neutral         Neutral\n",
      "\n",
      " Mean Squared Error: 0.0036282527344308232\n",
      "\n",
      " Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Bearish       1.00      0.67      0.80         6\n",
      "     Bullish       0.73      0.48      0.58        77\n",
      "     Neutral       0.86      0.95      0.91       283\n",
      "\n",
      "    accuracy                           0.85       366\n",
      "   macro avg       0.86      0.70      0.76       366\n",
      "weighted avg       0.84      0.85      0.84       366\n",
      "\n",
      "\n",
      " Confusion Matrix:\n",
      "[[  4   0   2]\n",
      " [  0  37  40]\n",
      " [  0  14 269]]\n",
      "\n",
      " Overall Accuracy: 84.70%\n"
     ]
    }
   ],
   "source": [
    "# Gradient Boosting Regression. (Supervised Algorithm)\n",
    "# Gradient Boosting Algorithm is a method where instead of building one big model, multiple models (Decision Tree) are built simultaneously where each \n",
    "# model is improving by the mistakes made by previous model.\n",
    "\n",
    "# Prediction of the stock market behaviour using Gradient Boosting Regression\n",
    "\n",
    "import pandas as pd                                          # pandas are used for data operations\n",
    "from sklearn.model_selection import train_test_split         # it is used to split the data (some for training and some for testing)\n",
    "from sklearn.ensemble import GradientBoostingRegressor       # used to fit a Gradient Boosting Regressor model\n",
    "from sklearn.preprocessing import StandardScaler             # used to rescale all the features so high value features don’t dominate low value features.\n",
    "                                                             # a particular value of the feature is subtracted by mean and divided by the variance\n",
    "from sklearn.metrics import mean_squared_error, classification_report, confusion_matrix, accuracy_score\n",
    "                                                             # it is used to obtain the observed results\n",
    "from collections import Counter                              # it is used to count the occurrence of a particular element\n",
    "\n",
    "# Loading the dataset\n",
    "df = pd.read_csv(\"C:/Users/luvkh/data/Datasets/stock_data_with_exogenous_variables.csv\")\n",
    "\n",
    "# Clean column names(remove all the characters that are not letter, number or underscore)\n",
    "df.columns = df.columns.str.replace(r'[^\\w]', '_', regex=True)\n",
    "\n",
    "# These columns are used to obtain Market_Confidence hence noting it down to drop these from the training data\n",
    "formula_columns = [\n",
    "    'Price_Change', 'StockMarket_Trend', 'Sentiment',\n",
    "    'ATR', 'Stochastic', 'Momentum', 'IsFedMeetingDay', 'CoreCPI'\n",
    "]\n",
    "\n",
    "# Defining the target column\n",
    "y = df['Market_Confidence']\n",
    "\n",
    "# Defining the training column\n",
    "X = df.drop(columns=formula_columns + ['Market_Confidence'])\n",
    "\n",
    "# Selecting only numeric features (Not including Dates, Top1 - Top25, All news)\n",
    "X = X.select_dtypes(include='number')\n",
    "\n",
    "# Split into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(         # 80% data is been trained and 20% of the data is been tested\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Scaling of the Training data and testing data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Fitting a Gradient Boosting Regression model\n",
    "model = GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, random_state=42) # 100 decision trees, slower the learning rate better the model\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predict confidence\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "# Class assigning based upon the Market_Confidence (Bullish/Bearish/Neutral)\n",
    "def confidence_to_class(conf):\n",
    "    if conf < 0.33:\n",
    "        return \"Bearish\"\n",
    "    elif conf <= 0.66:\n",
    "        return \"Neutral\"\n",
    "    else:\n",
    "        return \"Bullish\"\n",
    "\n",
    "y_test_class = [confidence_to_class(val) for val in y_test]        # Actual class of the Market_Confidence\n",
    "y_pred_class = [confidence_to_class(val) for val in y_pred]        # Predicted class of the Market_Confidence\n",
    "\n",
    "# Creating a DataFrame consisting of 4 columns\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Actual_Confidence': y_test,\n",
    "    'Predicted_Confidence': y_pred,\n",
    "    'Actual_Class': y_test_class,\n",
    "    'Predicted_Class': y_pred_class\n",
    "})\n",
    "print(\"\\n Top 10 Predictions vs Actuals:\")\n",
    "print(comparison_df.head(10))                                      # out of the 20% tested data, it shows the top 10\n",
    "\n",
    "# Evaluation\n",
    "\n",
    "# Mean square method is used to obtain how far our model predicted from the actual values.\n",
    "# It is calculating by subtracting predicted values with actual values(error) then square it and take average.\n",
    "print(\"\\n Mean Squared Error:\", mean_squared_error(y_test, y_pred))\n",
    "\n",
    "# Classification report gives detail about how well the model handled each class\n",
    "print(\"\\n Classification Report:\")\n",
    "print(classification_report(y_test_class, y_pred_class))\n",
    "\n",
    "# A table which gives actual(rows) vs predicted(columns) value\n",
    "print(\"\\n Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test_class, y_pred_class))\n",
    "\n",
    "# Print accuracy score\n",
    "accuracy = accuracy_score(y_test_class, y_pred_class)\n",
    "print(f\"\\n Overall Accuracy: {accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7309ca15-3a80-4836-9c80-02e3f89b5924",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Top 10 Predictions vs Actuals:\n",
      "      Actual_Confidence  Predicted_Confidence Actual_Class Predicted_Class\n",
      "247            0.572501              0.594097      Neutral         Neutral\n",
      "1293           0.639770              0.692315      Neutral         Bullish\n",
      "1562           0.423568              0.585731      Neutral         Neutral\n",
      "1101           0.255415              0.503842      Bearish         Neutral\n",
      "1161           0.635864              0.622813      Neutral         Neutral\n",
      "382            0.457954              0.522217      Neutral         Neutral\n",
      "1197           0.735602              0.696231      Bullish         Bullish\n",
      "777            0.513502              0.529144      Neutral         Neutral\n",
      "643            0.585349              0.596162      Neutral         Neutral\n",
      "275            0.511786              0.527390      Neutral         Neutral\n",
      "\n",
      " Mean Squared Error: 0.003190792360547677\n",
      "\n",
      " Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Bearish       1.00      0.67      0.80         6\n",
      "     Bullish       0.70      0.61      0.65        77\n",
      "     Neutral       0.89      0.93      0.91       283\n",
      "\n",
      "    accuracy                           0.86       366\n",
      "   macro avg       0.86      0.74      0.79       366\n",
      "weighted avg       0.85      0.86      0.85       366\n",
      "\n",
      "\n",
      " Confusion Matrix:\n",
      "[[  4   0   2]\n",
      " [  0  47  30]\n",
      " [  0  20 263]]\n",
      "\n",
      " Overall Accuracy: 85.79%\n"
     ]
    }
   ],
   "source": [
    "# XGBoost Regression. (Supervised Learning)\n",
    "# XGBoost (Extreme Gradient Boosting) is an optimized gradient boosting algorithm that is fast and highly accurate.\n",
    "# It builds multiple trees sequentially to correct previous errors and includes regularization to reduce overfitting.\n",
    "\n",
    "# Prediction of the stock market behaviour using XGBoost Regression\n",
    "\n",
    "import pandas as pd                                  # pandas are used for data operations\n",
    "from sklearn.model_selection import train_test_split # it is used to split the data (some for training and some for testing)\n",
    "from xgboost import XGBRegressor                     # used to fit an XGBoost Regression model\n",
    "from sklearn.preprocessing import StandardScaler     # used to rescale all the features used as no high value feature dominates low value feature.\n",
    "                                                     # a particular value of the feature is subtracted by mean and divided by the variance\n",
    "from sklearn.metrics import mean_squared_error, classification_report, confusion_matrix, accuracy_score\n",
    "                                                     # it is used to obtain the observed results\n",
    "from collections import Counter                      # it is used to count the occurance of a particular element\n",
    "\n",
    "# Loading the dataset\n",
    "df = pd.read_csv(\"C:/Users/luvkh/data/Datasets/stock_data_with_exogenous_variables.csv\")\n",
    "\n",
    "# Clean column names(remove all the characters that are not letter, number or underscore)\n",
    "df.columns = df.columns.str.replace(r'[^\\w]', '_', regex=True)\n",
    "\n",
    "# These columns are used to obtain Market_Confidence hence noting it down to drop these from the training data\n",
    "formula_columns = [\n",
    "    'Price_Change', 'StockMarket_Trend', 'Sentiment',\n",
    "    'ATR', 'Stochastic', 'Momentum', 'IsFedMeetingDay', 'CoreCPI'\n",
    "]\n",
    "\n",
    "# Defining the target column\n",
    "y = df['Market_Confidence']\n",
    "\n",
    "# Defining the training column\n",
    "X = df.drop(columns=formula_columns + ['Market_Confidence'])\n",
    "\n",
    "# Selecting only numeric features (Not including Dates, Top1 - Top25, All news)\n",
    "X = X.select_dtypes(include='number')\n",
    "\n",
    "# Split into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(       # 80% data is been trained and 20% of the data is been tested\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Scaling of the Training data and testing data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Fitting an XGBoost Regression model\n",
    "model = XGBRegressor(n_estimators=100, learning_rate=0.1, random_state=42) # same as Gradient\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predict confidence\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "# Class assigning based upon the Market_Confidence (Bullish/Bearish/Neutral)\n",
    "def confidence_to_class(conf):\n",
    "    if conf < 0.33:\n",
    "        return \"Bearish\"\n",
    "    elif conf <= 0.66:\n",
    "        return \"Neutral\"\n",
    "    else:\n",
    "        return \"Bullish\"\n",
    "\n",
    "y_test_class = [confidence_to_class(val) for val in y_test]        # Actual class of the Market_Confidence\n",
    "y_pred_class = [confidence_to_class(val) for val in y_pred]        # Predicted class of the Market_Confidence\n",
    "\n",
    "# Creating a DataFrame consisting of 4 columns\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Actual_Confidence': y_test,\n",
    "    'Predicted_Confidence': y_pred,\n",
    "    'Actual_Class': y_test_class,\n",
    "    'Predicted_Class': y_pred_class\n",
    "})\n",
    "print(\"\\n Top 10 Predictions vs Actuals:\")\n",
    "print(comparison_df.head(10))                                      # out of the 20% tested data, it shows the top 10\n",
    "\n",
    "# Evaluation\n",
    "\n",
    "# Mean square method is used to obtain how far our model predicted from the actual values.\n",
    "# It is calculating by subtracting predicted values with actual values(error) then square it and take average.\n",
    "print(\"\\n Mean Squared Error:\", mean_squared_error(y_test, y_pred))\n",
    "\n",
    "# Classification report gives detail about how well the model handled each class\n",
    "print(\"\\n Classification Report:\")\n",
    "print(classification_report(y_test_class, y_pred_class))\n",
    "\n",
    "# A table which gives actual(rows) vs predicted(columns) value\n",
    "print(\"\\n Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test_class, y_pred_class))\n",
    "\n",
    "# Print accuracy score\n",
    "accuracy = accuracy_score(y_test_class, y_pred_class)\n",
    "print(f\"\\n Overall Accuracy: {accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "843d930e-7ad4-4dff-8364-79e71c0e54cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000953 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5259\n",
      "[LightGBM] [Info] Number of data points in the train set: 1461, number of used features: 30\n",
      "[LightGBM] [Info] Start training from score 0.592248\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "\n",
      " Top 10 Predictions vs Actuals:\n",
      "      Actual_Confidence  Predicted_Confidence Actual_Class Predicted_Class\n",
      "247            0.572501              0.623226      Neutral         Neutral\n",
      "1293           0.639770              0.645474      Neutral         Neutral\n",
      "1562           0.423568              0.581528      Neutral         Neutral\n",
      "1101           0.255415              0.429706      Bearish         Neutral\n",
      "1161           0.635864              0.656699      Neutral         Neutral\n",
      "382            0.457954              0.506017      Neutral         Neutral\n",
      "1197           0.735602              0.593091      Bullish         Neutral\n",
      "777            0.513502              0.550374      Neutral         Neutral\n",
      "643            0.585349              0.584421      Neutral         Neutral\n",
      "275            0.511786              0.528213      Neutral         Neutral\n",
      "\n",
      " Mean Squared Error: 0.0032621176784638226\n",
      "\n",
      " Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Bearish       1.00      0.83      0.91         6\n",
      "     Bullish       0.68      0.53      0.60        77\n",
      "     Neutral       0.88      0.93      0.90       283\n",
      "\n",
      "    accuracy                           0.85       366\n",
      "   macro avg       0.85      0.77      0.80       366\n",
      "weighted avg       0.84      0.85      0.84       366\n",
      "\n",
      "\n",
      " Confusion Matrix:\n",
      "[[  5   0   1]\n",
      " [  0  41  36]\n",
      " [  0  19 264]]\n",
      "\n",
      " Overall Accuracy: 84.70%\n"
     ]
    }
   ],
   "source": [
    "# LightGBM Regression. (Supervised Learning)\n",
    "# LightGBM (Light Gradient Boosting Machine) is a high-performance gradient boosting framework.\n",
    "# It is optimized for speed and efficiency and is suitable for large datasets and fast training.\n",
    "\n",
    "# Prediction of the stock market behaviour using LightGBM Regression\n",
    "\n",
    "import pandas as pd                                      # pandas are used for data operations\n",
    "from sklearn.model_selection import train_test_split     # it is used to split the data (some for training and some for testing)\n",
    "from lightgbm import LGBMRegressor                       # used to fit a LightGBM Regression model\n",
    "from sklearn.preprocessing import StandardScaler         # used to rescale all the features used as no high value feature dominates low value feature.\n",
    "                                                         # a particular value of the feature is subtracted by mean and divided by the variance\n",
    "from sklearn.metrics import mean_squared_error, classification_report, confusion_matrix, accuracy_score\n",
    "                                                         # it is used to obtain the observed results\n",
    "from collections import Counter                          # it is used to count the occurance of a particular element\n",
    "\n",
    "# Loading the dataset\n",
    "df = pd.read_csv(\"C:/Users/luvkh/data/Datasets/stock_data_with_exogenous_variables.csv\")\n",
    "\n",
    "# Clean column names(remove all the characters that are not letter, number or underscore)\n",
    "df.columns = df.columns.str.replace(r'[^\\w]', '_', regex=True)\n",
    "\n",
    "# These columns are used to obtain Market_Confidence hence noting it down to drop these from the training data\n",
    "formula_columns = [\n",
    "    'Price_Change', 'StockMarket_Trend', 'Sentiment',\n",
    "    'ATR', 'Stochastic', 'Momentum', 'IsFedMeetingDay', 'CoreCPI'\n",
    "]\n",
    "\n",
    "# Defining the target column\n",
    "y = df['Market_Confidence']\n",
    "\n",
    "# Defining the training column\n",
    "X = df.drop(columns=formula_columns + ['Market_Confidence'])\n",
    "\n",
    "# Selecting only numeric features (Not including Dates, Top1 - Top25, All news)\n",
    "X = X.select_dtypes(include='number')\n",
    "\n",
    "# Split into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(     # 80% data is been trained and 20% of the data is been tested\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Scaling of the Training data and testing data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Fitting a LightGBM Regression model\n",
    "model = LGBMRegressor(n_estimators=100, learning_rate=0.1, max_depth=5, random_state=42) # same as aboe algorithms\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predict confidence\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "# Class assigning based upon the Market_Confidence (Bullish/Bearish/Neutral)\n",
    "def confidence_to_class(conf):\n",
    "    if conf < 0.33:\n",
    "        return \"Bearish\"\n",
    "    elif conf <= 0.66:\n",
    "        return \"Neutral\"\n",
    "    else:\n",
    "        return \"Bullish\"\n",
    "\n",
    "y_test_class = [confidence_to_class(val) for val in y_test]        # Actual class of the Market_Confidence\n",
    "y_pred_class = [confidence_to_class(val) for val in y_pred]        # Predicted class of the Market_Confidence\n",
    "\n",
    "# Creating a DataFrame consisting of 4 columns\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Actual_Confidence': y_test,\n",
    "    'Predicted_Confidence': y_pred,\n",
    "    'Actual_Class': y_test_class,\n",
    "    'Predicted_Class': y_pred_class\n",
    "})\n",
    "print(\"\\n Top 10 Predictions vs Actuals:\")\n",
    "print(comparison_df.head(10))                                      # out of the 20% tested data, it shows the top 10\n",
    "\n",
    "# Evaluation\n",
    "\n",
    "# Mean square method is used to obtain how far our model predicted from the actual values.\n",
    "# It is calculating by subtracting predicted values with actual values(error) then square it and take average.\n",
    "print(\"\\n Mean Squared Error:\", mean_squared_error(y_test, y_pred))\n",
    "\n",
    "# Classification report gives detail about how well the model handled each class\n",
    "print(\"\\n Classification Report:\")\n",
    "print(classification_report(y_test_class, y_pred_class))\n",
    "\n",
    "# A table which gives actual(rows) vs predicted(columns) value\n",
    "print(\"\\n Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test_class, y_pred_class))\n",
    "\n",
    "# Print accuracy score\n",
    "accuracy = accuracy_score(y_test_class, y_pred_class)\n",
    "print(f\"\\n Overall Accuracy: {accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aeda8398-c3bb-4efd-a5ef-10bee06b23c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Top 10 Predictions vs Actuals:\n",
      "      Actual_Confidence  Predicted_Confidence Actual_Class Predicted_Class\n",
      "247            0.572501              0.588520      Neutral         Neutral\n",
      "1293           0.639770              0.665065      Neutral         Bullish\n",
      "1562           0.423568              0.587688      Neutral         Neutral\n",
      "1101           0.255415              0.476847      Bearish         Neutral\n",
      "1161           0.635864              0.622817      Neutral         Neutral\n",
      "382            0.457954              0.535863      Neutral         Neutral\n",
      "1197           0.735602              0.608186      Bullish         Neutral\n",
      "777            0.513502              0.563085      Neutral         Neutral\n",
      "643            0.585349              0.591648      Neutral         Neutral\n",
      "275            0.511786              0.542333      Neutral         Neutral\n",
      "\n",
      " Mean Squared Error: 0.003954102658382247\n",
      "\n",
      " Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Bearish       1.00      0.67      0.80         6\n",
      "     Bullish       0.66      0.45      0.54        77\n",
      "     Neutral       0.86      0.94      0.90       283\n",
      "\n",
      "    accuracy                           0.83       366\n",
      "   macro avg       0.84      0.69      0.74       366\n",
      "weighted avg       0.82      0.83      0.82       366\n",
      "\n",
      "\n",
      " Confusion Matrix:\n",
      "[[  4   0   2]\n",
      " [  0  35  42]\n",
      " [  0  18 265]]\n",
      "\n",
      " Overall Accuracy: 83.06%\n"
     ]
    }
   ],
   "source": [
    "# CatBoost Regression. (Supervised Learning)\n",
    "# CatBoost (Categorical Boosting) is a gradient boosting algorithm that handles categorical variables automatically.\n",
    "# It is fast, accurate, and prevents overfitting using built-in regularization.\n",
    "\n",
    "# Prediction of the stock market behaviour using CatBoost Regression\n",
    "\n",
    "import pandas as pd                                      # pandas are used for data operations\n",
    "from sklearn.model_selection import train_test_split     # it is used to split the data (some for training and some for testing)\n",
    "from catboost import CatBoostRegressor                   # used to fit a CatBoost Regression model\n",
    "from sklearn.preprocessing import StandardScaler         # used to rescale all the features used as no high value feature dominates low value feature.\n",
    "                                                         # a particular value of the feature is subtracted by mean and divided by the variance\n",
    "from sklearn.metrics import mean_squared_error, classification_report, confusion_matrix, accuracy_score\n",
    "                                                         # it is used to obtain the observed results\n",
    "from collections import Counter                          # it is used to count the occurrence of a particular element\n",
    "\n",
    "# Loading the dataset\n",
    "df = pd.read_csv(\"C:/Users/luvkh/data/Datasets/stock_data_with_exogenous_variables.csv\")\n",
    "\n",
    "# Clean column names(remove all the characters that are not letter, number or underscore)\n",
    "df.columns = df.columns.str.replace(r'[^\\w]', '_', regex=True)\n",
    "\n",
    "# These columns are used to obtain Market_Confidence hence noting it down to drop these from the training data\n",
    "formula_columns = [\n",
    "    'Price_Change', 'StockMarket_Trend', 'Sentiment',\n",
    "    'ATR', 'Stochastic', 'Momentum', 'IsFedMeetingDay', 'CoreCPI'\n",
    "]\n",
    "\n",
    "# Defining the target column\n",
    "y = df['Market_Confidence']\n",
    "\n",
    "# Defining the training column\n",
    "X = df.drop(columns=formula_columns + ['Market_Confidence'])\n",
    "\n",
    "# Selecting only numeric features (Not including Dates, Top1 - Top25, All news)\n",
    "X = X.select_dtypes(include='number')\n",
    "\n",
    "# Split into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(     # 80% data is been trained and 20% of the data is been tested\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Scaling of the Training data and testing data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Fitting a CatBoost Regression model\n",
    "model = CatBoostRegressor(iterations=100, learning_rate=0.1, depth=5, verbose=0, random_state=42)\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predict confidence\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "# Class assigning based upon the Market_Confidence (Bullish/Bearish/Neutral)\n",
    "def confidence_to_class(conf):\n",
    "    if conf < 0.33:\n",
    "        return \"Bearish\"\n",
    "    elif conf <= 0.66:\n",
    "        return \"Neutral\"\n",
    "    else:\n",
    "        return \"Bullish\"\n",
    "\n",
    "y_test_class = [confidence_to_class(val) for val in y_test]        # Actual class of the Market_Confidence\n",
    "y_pred_class = [confidence_to_class(val) for val in y_pred]        # Predicted class of the Market_Confidence\n",
    "\n",
    "# Creating a DataFrame consisting of 4 columns\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Actual_Confidence': y_test,\n",
    "    'Predicted_Confidence': y_pred,\n",
    "    'Actual_Class': y_test_class,\n",
    "    'Predicted_Class': y_pred_class\n",
    "})\n",
    "print(\"\\n Top 10 Predictions vs Actuals:\")\n",
    "print(comparison_df.head(10))                                      # out of the 20% tested data, it shows the top 10\n",
    "\n",
    "# Evaluation\n",
    "\n",
    "# Mean square method is used to obtain how far our model predicted from the actual values.\n",
    "# It is calculating by subtracting predicted values with actual values(error) then square it and take average.\n",
    "print(\"\\n Mean Squared Error:\", mean_squared_error(y_test, y_pred))\n",
    "\n",
    "# Classification report gives detail about how well the model handled each class\n",
    "print(\"\\n Classification Report:\")\n",
    "print(classification_report(y_test_class, y_pred_class))\n",
    "\n",
    "# A table which gives actual(rows) vs predicted(columns) value\n",
    "print(\"\\n Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test_class, y_pred_class))\n",
    "\n",
    "# Print accuracy score\n",
    "accuracy = accuracy_score(y_test_class, y_pred_class)\n",
    "print(f\"\\n Overall Accuracy: {accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "31e23005-386b-4451-925f-1211771269ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Top 10 Predictions vs Actuals:\n",
      "      Actual_Confidence  Predicted_Confidence Actual_Class Predicted_Class\n",
      "247            0.572501              0.578944      Neutral         Neutral\n",
      "1293           0.639770              0.631419      Neutral         Neutral\n",
      "1562           0.423568              0.530219      Neutral         Neutral\n",
      "1101           0.255415              0.533908      Bearish         Neutral\n",
      "1161           0.635864              0.627519      Neutral         Neutral\n",
      "382            0.457954              0.516345      Neutral         Neutral\n",
      "1197           0.735602              0.531822      Bullish         Neutral\n",
      "777            0.513502              0.529600      Neutral         Neutral\n",
      "643            0.585349              0.620129      Neutral         Neutral\n",
      "275            0.511786              0.570003      Neutral         Neutral\n",
      "\n",
      " Mean Squared Error: 0.006974891625762776\n",
      "\n",
      " Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Bearish       0.00      0.00      0.00         6\n",
      "     Bullish       0.54      0.34      0.42        77\n",
      "     Neutral       0.82      0.92      0.87       283\n",
      "\n",
      "    accuracy                           0.78       366\n",
      "   macro avg       0.45      0.42      0.43       366\n",
      "weighted avg       0.75      0.78      0.76       366\n",
      "\n",
      "\n",
      " Confusion Matrix:\n",
      "[[  0   0   6]\n",
      " [  0  26  51]\n",
      " [  0  22 261]]\n",
      "\n",
      " Overall Accuracy: 78.42%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\luvkh\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\luvkh\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\luvkh\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Support Vector Regression (SVR).\n",
    "# Support Vector Regression is used just like Linear Regression which uses 2D plane to fit and seperatre the distinct values.\n",
    "# It is a non linear algorithm\n",
    "\n",
    "# Prediction of the stock market behaviour using Support Vector Regression\n",
    "\n",
    "import pandas as pd                                  # pandas are used for data operations\n",
    "from sklearn.model_selection import train_test_split # it is used to split the data (some for training and some for testing)\n",
    "from sklearn.svm import SVR                          # used to fit a Support Vector Regressor model\n",
    "from sklearn.preprocessing import StandardScaler     # used to rescale all the features used as no high value feature dominates low value feature.\n",
    "                                                     # a particular value of the feature is subtracted by mean and divided by the variance\n",
    "from sklearn.metrics import mean_squared_error, classification_report, confusion_matrix, accuracy_score\n",
    "                                                     # it is used to obtain the observed results\n",
    "from collections import Counter                      # it is used to count the occurance of a particular element\n",
    "\n",
    "# Loading the dataset\n",
    "df = pd.read_csv(\"C:/Users/luvkh/data/Datasets/stock_data_with_exogenous_variables.csv\")\n",
    "\n",
    "# Clean column names(remove all the characters that are not letter, number or underscore)\n",
    "df.columns = df.columns.str.replace(r'[^\\w]', '_', regex=True)\n",
    "\n",
    "# These columns are used to obtain Market_Confidence hence noting it down to drop these from the training data\n",
    "formula_columns = [\n",
    "    'Price_Change', 'StockMarket_Trend', 'Sentiment',\n",
    "    'ATR', 'Stochastic', 'Momentum', 'IsFedMeetingDay', 'CoreCPI'\n",
    "]\n",
    "\n",
    "# Defining the target column\n",
    "y = df['Market_Confidence']\n",
    "\n",
    "# Defining the training column\n",
    "X = df.drop(columns=formula_columns + ['Market_Confidence'])\n",
    "\n",
    "# Selecting only numeric features (Not including Dates, Top1 - Top25, All news)\n",
    "X = X.select_dtypes(include='number')\n",
    "\n",
    "# Split into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(       # 80% data is been trained and 20% of the data is been tested\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Scaling of the Training data and testing data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Fitting a Support Vector Regression model\n",
    "model = SVR(kernel='rbf', C=1.0, epsilon=0.1)\n",
    "# kernel='rbf'\tUse a non-linear kernel to fit curved patterns\n",
    "# C=1.0\tControls penalty for errors (how hard the model tries to avoid mistakes)\n",
    "# epsilon=0.1\tSets the margin of tolerance – the zone where errors are not punished\n",
    "\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predict confidence\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "# Class assigning based upon the Market_Confidence (Bullish/Bearish/Neutral)\n",
    "def confidence_to_class(conf):\n",
    "    if conf < 0.33:\n",
    "        return \"Bearish\"\n",
    "    elif conf <= 0.66:\n",
    "        return \"Neutral\"\n",
    "    else:\n",
    "        return \"Bullish\"\n",
    "\n",
    "y_test_class = [confidence_to_class(val) for val in y_test]        # Actual class of the Market_Confidence\n",
    "y_pred_class = [confidence_to_class(val) for val in y_pred]        # Predicted class of the Market_Confidence\n",
    "\n",
    "# Creating a DataFrame consisting of 4 columns\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Actual_Confidence': y_test,\n",
    "    'Predicted_Confidence': y_pred,\n",
    "    'Actual_Class': y_test_class,\n",
    "    'Predicted_Class': y_pred_class\n",
    "})\n",
    "print(\"\\n Top 10 Predictions vs Actuals:\")\n",
    "print(comparison_df.head(10))                                      # out of the 20% tested data, it shows the top 10\n",
    "\n",
    "# Evaluation\n",
    "\n",
    "# Mean square method is used to obtain how far our model predicted from the actual values.\n",
    "# It is calculating by subtracting predicted values with actual values(error) then square it and take average.\n",
    "print(\"\\n Mean Squared Error:\", mean_squared_error(y_test, y_pred))\n",
    "\n",
    "# Classification report gives detail about how well the model handled each class\n",
    "print(\"\\n Classification Report:\")\n",
    "print(classification_report(y_test_class, y_pred_class))\n",
    "\n",
    "# A table which gives actual(rows) vs predicted(columns) value\n",
    "print(\"\\n Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test_class, y_pred_class))\n",
    "\n",
    "# Print accuracy score\n",
    "accuracy = accuracy_score(y_test_class, y_pred_class)\n",
    "print(f\"\\n Overall Accuracy: {accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2061e78f-b5b1-46bd-bb20-b6aa45d4654f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "827ee6c8-953d-4165-ada3-2ed0abcc32de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deep Learning Algorithms used to predict the Stock Market Behaviour with Exogenous variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3d4f7147-d1a2-42ee-bea3-8447b02a1ec1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\luvkh\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n",
      "\n",
      " Top 10 Predictions vs Actuals:\n",
      "      Actual_Confidence  Predicted_Confidence Actual_Class Predicted_Class\n",
      "247            0.572501              0.613181      Neutral         Neutral\n",
      "1293           0.639770              0.705979      Neutral         Bullish\n",
      "1562           0.423568              0.543546      Neutral         Neutral\n",
      "1101           0.255415              0.511410      Bearish         Neutral\n",
      "1161           0.635864              0.709671      Neutral         Bullish\n",
      "382            0.457954              0.504433      Neutral         Neutral\n",
      "1197           0.735602              0.527491      Bullish         Neutral\n",
      "777            0.513502              0.568437      Neutral         Neutral\n",
      "643            0.585349              0.551178      Neutral         Neutral\n",
      "275            0.511786              0.551440      Neutral         Neutral\n",
      "\n",
      " Mean Squared Error: 0.004995286408950402\n",
      "\n",
      " Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Bearish       0.60      0.50      0.55         6\n",
      "     Bullish       0.53      0.62      0.57        77\n",
      "     Neutral       0.88      0.84      0.86       283\n",
      "\n",
      "    accuracy                           0.79       366\n",
      "   macro avg       0.67      0.66      0.66       366\n",
      "weighted avg       0.80      0.79      0.80       366\n",
      "\n",
      "\n",
      " Confusion Matrix:\n",
      "[[  3   0   3]\n",
      " [  0  48  29]\n",
      " [  2  42 239]]\n",
      "\n",
      " Overall Accuracy: 79.23%\n"
     ]
    }
   ],
   "source": [
    "# MLP Regression. (Supervised Learning)\n",
    "# MLP (Multilayer Perceptron) is a deep learning model that consists of layers of neurons.\n",
    "# It is used to predict continuous values like Market_Confidence by learning patterns from input features.\n",
    "# It works like an advanced version of Linear Regression, but with hidden layers for better learning.\n",
    "\n",
    "# Prediction of the stock market behaviour using MLP Regression\n",
    "\n",
    "import pandas as pd                                          # pandas are used for data operations\n",
    "from sklearn.model_selection import train_test_split         # it is used to split the data (some for training and some for testing)\n",
    "from sklearn.preprocessing import StandardScaler             # used to rescale all the features used as no high value feature dominates low value feature.\n",
    "                                                             # a particular value of the feature is subtracted by mean and divided by the variance\n",
    "from sklearn.metrics import mean_squared_error, classification_report, confusion_matrix, accuracy_score\n",
    "                                                             # it is used to obtain the observed results\n",
    "from collections import Counter                              # it is used to count the occurrence of a particular element\n",
    "import tensorflow as tf                                      # tensorflow is used for building deep learning models\n",
    "from tensorflow.keras.models import Sequential               # Sequential is used to define the model structure\n",
    "from tensorflow.keras.layers import Dense                    # Dense layers are fully connected layers in the neural network\n",
    "from tensorflow.keras.optimizers import Adam                 # Adam is an optimizer used to update weights in neural networks\n",
    "\n",
    "# Loading the dataset\n",
    "df = pd.read_csv(\"C:/Users/luvkh/data/Datasets/stock_data_with_exogenous_variables.csv\")\n",
    "\n",
    "# Clean column names(remove all the characters that are not letter, number or underscore)\n",
    "df.columns = df.columns.str.replace(r'[^\\w]', '_', regex=True)\n",
    "\n",
    "# These columns are used to obtain Market_Confidence hence noting it down to drop these from the training data\n",
    "formula_columns = [\n",
    "    'Price_Change', 'StockMarket_Trend', 'Sentiment',\n",
    "    'ATR', 'Stochastic', 'Momentum', 'IsFedMeetingDay', 'CoreCPI'\n",
    "]\n",
    "\n",
    "# Defining the target column\n",
    "y = df['Market_Confidence']\n",
    "\n",
    "# Defining the training column\n",
    "X = df.drop(columns=formula_columns + ['Market_Confidence'])\n",
    "\n",
    "# Selecting only numeric features (Not including Dates, Top1 - Top25, All news)\n",
    "X = X.select_dtypes(include='number')\n",
    "\n",
    "# Split into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(         # 80% data is been trained and 20% of the data is been tested\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Scaling of the Training data and testing data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Fitting a MLP Regression model\n",
    "model = Sequential([\n",
    "    Dense(64, activation='relu', input_shape=(X_train_scaled.shape[1],)),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')                             # Output value between 0 and 1 (because Market_Confidence is in that range)\n",
    "])\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='mse') # Compiling the model using mean squared error as loss\n",
    "model.fit(X_train_scaled, y_train, epochs=100, batch_size=32, validation_split=0.1, verbose=0) # Training the model\n",
    "\n",
    "# Predict confidence\n",
    "y_pred = model.predict(X_test_scaled).flatten()\n",
    "\n",
    "# Class assigning based upon the Market_Confidence (Bullish/Bearish/Neutral)\n",
    "def confidence_to_class(conf):\n",
    "    if conf < 0.33:\n",
    "        return \"Bearish\"\n",
    "    elif conf <= 0.66:\n",
    "        return \"Neutral\"\n",
    "    else:\n",
    "        return \"Bullish\"\n",
    "\n",
    "y_test_class = [confidence_to_class(val) for val in y_test]        # Actual class of the Market_Confidence\n",
    "y_pred_class = [confidence_to_class(val) for val in y_pred]        # Predicted class of the Market_Confidence\n",
    "\n",
    "# Creating a DataFrame consisting of 4 columns\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Actual_Confidence': y_test,\n",
    "    'Predicted_Confidence': y_pred,\n",
    "    'Actual_Class': y_test_class,\n",
    "    'Predicted_Class': y_pred_class\n",
    "})\n",
    "print(\"\\n Top 10 Predictions vs Actuals:\")\n",
    "print(comparison_df.head(10))                                      # out of the 20% tested data, it shows the top 10\n",
    "\n",
    "# Evaluation\n",
    "\n",
    "# Mean square method is used to obtain how far our model predicted from the actual values.\n",
    "# It is calculated by subtracting predicted values with actual values(error) then squaring it and taking the average.\n",
    "print(\"\\n Mean Squared Error:\", mean_squared_error(y_test, y_pred))\n",
    "\n",
    "# Classification report gives detail about how well the model handled each class\n",
    "print(\"\\n Classification Report:\")\n",
    "print(classification_report(y_test_class, y_pred_class))\n",
    "\n",
    "# A table which gives actual(rows) vs predicted(columns) value\n",
    "print(\"\\n Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test_class, y_pred_class))\n",
    "\n",
    "# Print accuracy score\n",
    "accuracy = accuracy_score(y_test_class, y_pred_class)\n",
    "print(f\"\\n Overall Accuracy: {accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5e429975-a07b-470f-9743-5c8c57f16c54",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\luvkh\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step\n",
      "\n",
      " Top 10 Predictions vs Actuals:\n",
      "   Actual_Confidence  Predicted_Confidence Actual_Class Predicted_Class\n",
      "0           0.626303              0.630695      Neutral         Neutral\n",
      "1           0.581940              0.478558      Neutral         Neutral\n",
      "2           0.606372              0.560391      Neutral         Neutral\n",
      "3           0.568237              0.496782      Neutral         Neutral\n",
      "4           0.485682              0.463311      Neutral         Neutral\n",
      "5           0.655102              0.646418      Neutral         Neutral\n",
      "6           0.703647              0.706889      Bullish         Bullish\n",
      "7           0.612046              0.613495      Neutral         Neutral\n",
      "8           0.590268              0.638489      Neutral         Neutral\n",
      "9           0.574182              0.595111      Neutral         Neutral\n",
      "\n",
      " Mean Squared Error: 0.0044497249743812965\n",
      "\n",
      " Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Bearish       0.67      0.50      0.57         4\n",
      "     Bullish       0.74      0.60      0.66        87\n",
      "     Neutral       0.87      0.93      0.90       274\n",
      "\n",
      "    accuracy                           0.85       365\n",
      "   macro avg       0.76      0.68      0.71       365\n",
      "weighted avg       0.84      0.85      0.84       365\n",
      "\n",
      "\n",
      " Confusion Matrix:\n",
      "[[  2   0   2]\n",
      " [  0  52  35]\n",
      " [  1  18 255]]\n",
      "\n",
      " Overall Accuracy: 84.66%\n"
     ]
    }
   ],
   "source": [
    "# LSTM Regression. (Supervised Learning)\n",
    "# LSTM is a type of deep learning model (RNN) used for sequential data. It remembers past values to better predict future values.\n",
    "# It is best suited for time series tasks like stock prediction, where the order of data matters.\n",
    "\n",
    "# Prediction of the stock market behaviour using LSTM Regression\n",
    "\n",
    "import pandas as pd                                          # pandas are used for data operations\n",
    "from sklearn.model_selection import train_test_split         # it is used to split the data (some for training and some for testing)\n",
    "from sklearn.preprocessing import StandardScaler             # used to rescale all the features\n",
    "from sklearn.metrics import mean_squared_error, classification_report, confusion_matrix, accuracy_score\n",
    "                                                             # used to evaluate the model\n",
    "from collections import Counter                              # it is used to count the occurrence of each class\n",
    "import numpy as np                                           \n",
    "import tensorflow as tf                                      # tensorflow for deep learning\n",
    "from tensorflow.keras.models import Sequential               # Sequential to define model\n",
    "from tensorflow.keras.layers import LSTM, Dense              # LSTM and Dense layers\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"C:/Users/luvkh/data/Datasets/stock_data_with_exogenous_variables.csv\")\n",
    "\n",
    "# Clean column names\n",
    "df.columns = df.columns.str.replace(r'[^\\w]', '_', regex=True)\n",
    "\n",
    "# Columns to drop from training (used in target calculation)\n",
    "formula_columns = [\n",
    "    'Price_Change', 'StockMarket_Trend', 'Sentiment',\n",
    "    'ATR', 'Stochastic', 'Momentum', 'IsFedMeetingDay', 'CoreCPI'\n",
    "]\n",
    "\n",
    "# Define target and features\n",
    "y = df['Market_Confidence']\n",
    "X = df.drop(columns=formula_columns + ['Market_Confidence'])\n",
    "\n",
    "# Use only numeric columns\n",
    "X = X.select_dtypes(include='number')\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Convert data into time-based sequences for LSTM (use 5 time steps)\n",
    "time_steps = 5\n",
    "\n",
    "def create_sequences(X, y, time_steps=5):\n",
    "    Xs, ys = [], []\n",
    "    for i in range(len(X) - time_steps):\n",
    "        Xs.append(X[i:i+time_steps])\n",
    "        ys.append(y[i+time_steps])\n",
    "    return np.array(Xs), np.array(ys)\n",
    "\n",
    "X_seq, y_seq = create_sequences(X_scaled, y.values, time_steps)\n",
    "\n",
    "# Split into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_seq, y_seq, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define LSTM model\n",
    "model = Sequential([\n",
    "    LSTM(64, input_shape=(X_train.shape[1], X_train.shape[2]), return_sequences=False),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')   # Output between 0 and 1\n",
    "])\n",
    "\n",
    "# Compile model\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='mse')\n",
    "\n",
    "# Train model\n",
    "model.fit(X_train, y_train, epochs=50, batch_size=32, validation_split=0.1, verbose=0)\n",
    "\n",
    "# Predict\n",
    "y_pred = model.predict(X_test).flatten()\n",
    "\n",
    "# Convert predictions to class labels\n",
    "def confidence_to_class(conf):\n",
    "    if conf < 0.33:\n",
    "        return \"Bearish\"\n",
    "    elif conf <= 0.66:\n",
    "        return \"Neutral\"\n",
    "    else:\n",
    "        return \"Bullish\"\n",
    "\n",
    "y_test_class = [confidence_to_class(val) for val in y_test]\n",
    "y_pred_class = [confidence_to_class(val) for val in y_pred]\n",
    "\n",
    "# Create comparison dataframe\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Actual_Confidence': y_test,\n",
    "    'Predicted_Confidence': y_pred,\n",
    "    'Actual_Class': y_test_class,\n",
    "    'Predicted_Class': y_pred_class\n",
    "})\n",
    "print(\"\\n Top 10 Predictions vs Actuals:\")\n",
    "print(comparison_df.head(10))\n",
    "\n",
    "# Evaluation\n",
    "print(\"\\n Mean Squared Error:\", mean_squared_error(y_test, y_pred))\n",
    "print(\"\\n Classification Report:\")\n",
    "print(classification_report(y_test_class, y_pred_class))\n",
    "print(\"\\n Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test_class, y_pred_class))\n",
    "accuracy = accuracy_score(y_test_class, y_pred_class)\n",
    "print(f\"\\n Overall Accuracy: {accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a0aa0f49-5b81-4cc2-b99a-4f8fb575938c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\luvkh\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\n",
      " Top 10 Predictions vs Actuals:\n",
      "   Actual_Confidence  Predicted_Confidence Actual_Class Predicted_Class\n",
      "0           0.626303              0.586069      Neutral         Neutral\n",
      "1           0.581940              0.518853      Neutral         Neutral\n",
      "2           0.606372              0.567551      Neutral         Neutral\n",
      "3           0.568237              0.599833      Neutral         Neutral\n",
      "4           0.485682              0.554576      Neutral         Neutral\n",
      "5           0.655102              0.596630      Neutral         Neutral\n",
      "6           0.703647              0.624043      Bullish         Neutral\n",
      "7           0.612046              0.678469      Neutral         Bullish\n",
      "8           0.590268              0.637863      Neutral         Neutral\n",
      "9           0.574182              0.557567      Neutral         Neutral\n",
      "\n",
      " Mean Squared Error: 0.0063193712447092015\n",
      "\n",
      " Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Bearish       1.00      0.25      0.40         4\n",
      "     Bullish       0.57      0.59      0.58        87\n",
      "     Neutral       0.86      0.86      0.86       274\n",
      "\n",
      "    accuracy                           0.79       365\n",
      "   macro avg       0.81      0.57      0.61       365\n",
      "weighted avg       0.79      0.79      0.79       365\n",
      "\n",
      "\n",
      " Confusion Matrix:\n",
      "[[  1   0   3]\n",
      " [  0  51  36]\n",
      " [  0  38 236]]\n",
      "\n",
      " Overall Accuracy: 78.90%\n"
     ]
    }
   ],
   "source": [
    "# 1D CNN Regression. (Supervised Learning)\n",
    "# A 1D Convolutional Neural Network learns from sequences by applying filters to detect patterns in time steps.\n",
    "# It is useful for time-based regression problems like stock prediction, where local patterns in recent time steps matter.\n",
    "\n",
    "# Prediction of the stock market behaviour using 1D CNN Regression\n",
    "\n",
    "import pandas as pd                                          # pandas are used for data operations\n",
    "from sklearn.model_selection import train_test_split         # it is used to split the data (some for training and some for testing)\n",
    "from sklearn.preprocessing import StandardScaler             # used to rescale all the features\n",
    "from sklearn.metrics import mean_squared_error, classification_report, confusion_matrix, accuracy_score\n",
    "                                                             # used to evaluate the model\n",
    "from collections import Counter                              # it is used to count the occurrence of each class\n",
    "import numpy as np                                           \n",
    "import tensorflow as tf                                      # tensorflow for deep learning\n",
    "from tensorflow.keras.models import Sequential               # Sequential to define model\n",
    "from tensorflow.keras.layers import Conv1D, Dense, Flatten   # 1D Convolution and fully connected layers\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"C:/Users/luvkh/data/Datasets/stock_data_with_exogenous_variables.csv\")\n",
    "\n",
    "# Clean column names\n",
    "df.columns = df.columns.str.replace(r'[^\\w]', '_', regex=True)\n",
    "\n",
    "# Columns to drop from training (used in target calculation)\n",
    "formula_columns = [\n",
    "    'Price_Change', 'StockMarket_Trend', 'Sentiment',\n",
    "    'ATR', 'Stochastic', 'Momentum', 'IsFedMeetingDay', 'CoreCPI'\n",
    "]\n",
    "\n",
    "# Define target and features\n",
    "y = df['Market_Confidence']\n",
    "X = df.drop(columns=formula_columns + ['Market_Confidence'])\n",
    "\n",
    "# Use only numeric columns\n",
    "X = X.select_dtypes(include='number')\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Convert data into time-based sequences for 1D CNN (use 5 time steps)\n",
    "time_steps = 5\n",
    "\n",
    "def create_sequences(X, y, time_steps=5):\n",
    "    Xs, ys = [], []\n",
    "    for i in range(len(X) - time_steps):\n",
    "        Xs.append(X[i:i+time_steps])\n",
    "        ys.append(y[i+time_steps])\n",
    "    return np.array(Xs), np.array(ys)\n",
    "\n",
    "X_seq, y_seq = create_sequences(X_scaled, y.values, time_steps)\n",
    "\n",
    "# Split into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_seq, y_seq, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define 1D CNN model\n",
    "model = Sequential([\n",
    "    Conv1D(filters=64, kernel_size=2, activation='relu', input_shape=(X_train.shape[1], X_train.shape[2])),\n",
    "    Flatten(),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')   # Output between 0 and 1\n",
    "])\n",
    "\n",
    "# Compile model\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='mse')\n",
    "\n",
    "# Train model\n",
    "model.fit(X_train, y_train, epochs=50, batch_size=32, validation_split=0.1, verbose=0)\n",
    "\n",
    "# Predict\n",
    "y_pred = model.predict(X_test).flatten()\n",
    "\n",
    "# Convert predictions to class labels\n",
    "def confidence_to_class(conf):\n",
    "    if conf < 0.33:\n",
    "        return \"Bearish\"\n",
    "    elif conf <= 0.66:\n",
    "        return \"Neutral\"\n",
    "    else:\n",
    "        return \"Bullish\"\n",
    "\n",
    "y_test_class = [confidence_to_class(val) for val in y_test]\n",
    "y_pred_class = [confidence_to_class(val) for val in y_pred]\n",
    "\n",
    "# Create comparison dataframe\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Actual_Confidence': y_test,\n",
    "    'Predicted_Confidence': y_pred,\n",
    "    'Actual_Class': y_test_class,\n",
    "    'Predicted_Class': y_pred_class\n",
    "})\n",
    "print(\"\\n Top 10 Predictions vs Actuals:\")\n",
    "print(comparison_df.head(10))\n",
    "\n",
    "# Evaluation\n",
    "print(\"\\n Mean Squared Error:\", mean_squared_error(y_test, y_pred))\n",
    "print(\"\\n Classification Report:\")\n",
    "print(classification_report(y_test_class, y_pred_class))\n",
    "print(\"\\n Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test_class, y_pred_class))\n",
    "accuracy = accuracy_score(y_test_class, y_pred_class)\n",
    "print(f\"\\n Overall Accuracy: {accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9dd4f1b0-9fb6-4f10-84f3-964bf253242d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pytorch-tabnet --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "11acc255-6c2f-4dc8-ae67-bdeff6ad9702",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\luvkh\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step\n",
      "\n",
      " Top 10 Predictions vs Actuals:\n",
      "   Actual_Confidence  Predicted_Confidence Actual_Class Predicted_Class\n",
      "0           0.626303              0.608351      Neutral         Neutral\n",
      "1           0.581940              0.532641      Neutral         Neutral\n",
      "2           0.606372              0.621988      Neutral         Neutral\n",
      "3           0.568237              0.556664      Neutral         Neutral\n",
      "4           0.485682              0.525000      Neutral         Neutral\n",
      "5           0.655102              0.610133      Neutral         Neutral\n",
      "6           0.703647              0.618184      Bullish         Neutral\n",
      "7           0.612046              0.633621      Neutral         Neutral\n",
      "8           0.590268              0.679550      Neutral         Bullish\n",
      "9           0.574182              0.611146      Neutral         Neutral\n",
      "\n",
      " Mean Squared Error: 0.004745434981333837\n",
      "\n",
      " Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Bearish       1.00      0.50      0.67         4\n",
      "     Bullish       0.69      0.71      0.70        87\n",
      "     Neutral       0.90      0.90      0.90       274\n",
      "\n",
      "    accuracy                           0.85       365\n",
      "   macro avg       0.86      0.70      0.76       365\n",
      "weighted avg       0.85      0.85      0.85       365\n",
      "\n",
      "\n",
      " Confusion Matrix:\n",
      "[[  2   0   2]\n",
      " [  0  62  25]\n",
      " [  0  28 246]]\n",
      "\n",
      " Overall Accuracy: 84.93%\n"
     ]
    }
   ],
   "source": [
    "# GRU Regression. (Supervised Learning)\n",
    "# GRU is a recurrent neural network that learns time-based patterns.\n",
    "# It is similar to LSTM but faster and uses fewer parameters. Ideal for sequence data like stock predictions.\n",
    "\n",
    "# Prediction of the stock market behaviour using GRU Regression\n",
    "\n",
    "import pandas as pd                                          # pandas are used for data operations\n",
    "from sklearn.model_selection import train_test_split         # split the dataset into train and test sets\n",
    "from sklearn.preprocessing import StandardScaler             # normalize features\n",
    "from sklearn.metrics import mean_squared_error, classification_report, confusion_matrix, accuracy_score\n",
    "                                                             # evaluation metrics\n",
    "from collections import Counter                              # count class distributions\n",
    "import numpy as np\n",
    "import tensorflow as tf                                      # deep learning framework\n",
    "from tensorflow.keras.models import Sequential               # used to define the GRU model\n",
    "from tensorflow.keras.layers import GRU, Dense               # GRU and Dense layers\n",
    "from tensorflow.keras.optimizers import Adam                 # optimizer for training\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"C:/Users/luvkh/data/Datasets/stock_data_with_exogenous_variables.csv\")\n",
    "\n",
    "# Clean column names\n",
    "df.columns = df.columns.str.replace(r'[^\\w]', '_', regex=True)\n",
    "\n",
    "# Drop columns used in Market_Confidence formula\n",
    "formula_columns = [\n",
    "    'Price_Change', 'StockMarket_Trend', 'Sentiment',\n",
    "    'ATR', 'Stochastic', 'Momentum', 'IsFedMeetingDay', 'CoreCPI'\n",
    "]\n",
    "\n",
    "# Define target and features\n",
    "y = df['Market_Confidence']\n",
    "X = df.drop(columns=formula_columns + ['Market_Confidence'])\n",
    "\n",
    "# Keep only numeric columns\n",
    "X = X.select_dtypes(include='number')\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Convert to sequences (time steps)\n",
    "time_steps = 5\n",
    "def create_sequences(X, y, time_steps=5):\n",
    "    Xs, ys = [], []\n",
    "    for i in range(len(X) - time_steps):\n",
    "        Xs.append(X[i:i+time_steps])\n",
    "        ys.append(y[i+time_steps])\n",
    "    return np.array(Xs), np.array(ys)\n",
    "\n",
    "X_seq, y_seq = create_sequences(X_scaled, y.values, time_steps)\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_seq, y_seq, test_size=0.2, random_state=42)\n",
    "\n",
    "# Build GRU model\n",
    "model = Sequential([\n",
    "    GRU(64, input_shape=(X_train.shape[1], X_train.shape[2]), return_sequences=False),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')   # Output between 0 and 1\n",
    "])\n",
    "\n",
    "# Compile model\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='mse')\n",
    "\n",
    "# Train model\n",
    "model.fit(X_train, y_train, epochs=50, batch_size=32, validation_split=0.1, verbose=0)\n",
    "\n",
    "# Predict\n",
    "y_pred = model.predict(X_test).flatten()\n",
    "\n",
    "# Convert to class labels\n",
    "def confidence_to_class(conf):\n",
    "    if conf < 0.33:\n",
    "        return \"Bearish\"\n",
    "    elif conf <= 0.66:\n",
    "        return \"Neutral\"\n",
    "    else:\n",
    "        return \"Bullish\"\n",
    "\n",
    "y_test_class = [confidence_to_class(val) for val in y_test]\n",
    "y_pred_class = [confidence_to_class(val) for val in y_pred]\n",
    "\n",
    "# Create comparison dataframe\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Actual_Confidence': y_test,\n",
    "    'Predicted_Confidence': y_pred,\n",
    "    'Actual_Class': y_test_class,\n",
    "    'Predicted_Class': y_pred_class\n",
    "})\n",
    "print(\"\\n Top 10 Predictions vs Actuals:\")\n",
    "print(comparison_df.head(10))\n",
    "\n",
    "# Evaluation\n",
    "print(\"\\n Mean Squared Error:\", mean_squared_error(y_test, y_pred))\n",
    "print(\"\\n Classification Report:\")\n",
    "print(classification_report(y_test_class, y_pred_class))\n",
    "print(\"\\n Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test_class, y_pred_class))\n",
    "accuracy = accuracy_score(y_test_class, y_pred_class)\n",
    "print(f\"\\n Overall Accuracy: {accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "68bed992-56fa-43aa-b676-ef97f27a65cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step\n",
      "\n",
      " Top 10 Predictions vs Actuals:\n",
      "   Actual_Confidence  Predicted_Confidence Actual_Class Predicted_Class\n",
      "0           0.626303              0.591683      Neutral         Neutral\n",
      "1           0.581940              0.532231      Neutral         Neutral\n",
      "2           0.606372              0.590778      Neutral         Neutral\n",
      "3           0.568237              0.600054      Neutral         Neutral\n",
      "4           0.485682              0.432901      Neutral         Neutral\n",
      "5           0.655102              0.660102      Neutral         Bullish\n",
      "6           0.703647              0.737073      Bullish         Bullish\n",
      "7           0.612046              0.665465      Neutral         Bullish\n",
      "8           0.590268              0.647631      Neutral         Neutral\n",
      "9           0.574182              0.569720      Neutral         Neutral\n",
      "\n",
      " Mean Squared Error: 0.005249526077902524\n",
      "\n",
      " Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Bearish       0.20      0.25      0.22         4\n",
      "     Bullish       0.71      0.61      0.65        87\n",
      "     Neutral       0.87      0.91      0.89       274\n",
      "\n",
      "    accuracy                           0.83       365\n",
      "   macro avg       0.59      0.59      0.59       365\n",
      "weighted avg       0.82      0.83      0.82       365\n",
      "\n",
      "\n",
      " Confusion Matrix:\n",
      "[[  1   0   3]\n",
      " [  0  53  34]\n",
      " [  4  22 248]]\n",
      "\n",
      " Overall Accuracy: 82.74%\n"
     ]
    }
   ],
   "source": [
    "# Transformer Regression. (Supervised Learning)\n",
    "# Transformer models use attention to capture long-range relationships in time series data.\n",
    "# Unlike LSTM/GRU, they don't process data sequentially, making them faster and better for long sequences.\n",
    "\n",
    "# Prediction of the stock market behaviour using Transformer Regression\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, classification_report, confusion_matrix, accuracy_score\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, LayerNormalization, Dropout\n",
    "from tensorflow.keras.layers import MultiHeadAttention, Add, GlobalAveragePooling1D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"C:/Users/luvkh/data/Datasets/stock_data_with_exogenous_variables.csv\")\n",
    "df.columns = df.columns.str.replace(r'[^\\w]', '_', regex=True)\n",
    "\n",
    "# Define features and target\n",
    "formula_columns = [\n",
    "    'Price_Change', 'StockMarket_Trend', 'Sentiment',\n",
    "    'ATR', 'Stochastic', 'Momentum', 'IsFedMeetingDay', 'CoreCPI'\n",
    "]\n",
    "y = df['Market_Confidence']\n",
    "X = df.drop(columns=formula_columns + ['Market_Confidence'])\n",
    "X = X.select_dtypes(include='number')\n",
    "\n",
    "# Scale data\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Create time sequences\n",
    "time_steps = 5\n",
    "def create_sequences(X, y, time_steps=5):\n",
    "    Xs, ys = [], []\n",
    "    for i in range(len(X) - time_steps):\n",
    "        Xs.append(X[i:i+time_steps])\n",
    "        ys.append(y[i+time_steps])\n",
    "    return np.array(Xs), np.array(ys)\n",
    "\n",
    "X_seq, y_seq = create_sequences(X_scaled, y.values, time_steps)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_seq, y_seq, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define Transformer block\n",
    "def transformer_encoder(inputs, num_heads=4, key_dim=32, ff_dim=64, dropout=0.1):\n",
    "    attn_output = MultiHeadAttention(num_heads=num_heads, key_dim=key_dim)(inputs, inputs)\n",
    "    attn_output = Dropout(dropout)(attn_output)\n",
    "    out1 = LayerNormalization(epsilon=1e-6)(inputs + attn_output)\n",
    "\n",
    "    ffn_output = Dense(ff_dim, activation='relu')(out1)\n",
    "    ffn_output = Dense(inputs.shape[-1])(ffn_output)\n",
    "    ffn_output = Dropout(dropout)(ffn_output)\n",
    "    return LayerNormalization(epsilon=1e-6)(out1 + ffn_output)\n",
    "\n",
    "# Build Transformer model\n",
    "input_shape = X_train.shape[1:]\n",
    "inputs = Input(shape=input_shape)\n",
    "x = transformer_encoder(inputs)\n",
    "x = GlobalAveragePooling1D()(x)\n",
    "x = Dense(64, activation='relu')(x)\n",
    "x = Dense(32, activation='relu')(x)\n",
    "outputs = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "model = Model(inputs, outputs)\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='mse')\n",
    "\n",
    "# Train model\n",
    "model.fit(X_train, y_train, epochs=50, batch_size=32, validation_split=0.1, verbose=0)\n",
    "\n",
    "# Predict\n",
    "y_pred = model.predict(X_test).flatten()\n",
    "\n",
    "# Convert to classes\n",
    "def confidence_to_class(conf):\n",
    "    if conf < 0.33:\n",
    "        return \"Bearish\"\n",
    "    elif conf <= 0.66:\n",
    "        return \"Neutral\"\n",
    "    else:\n",
    "        return \"Bullish\"\n",
    "\n",
    "y_test_class = [confidence_to_class(val) for val in y_test]\n",
    "y_pred_class = [confidence_to_class(val) for val in y_pred]\n",
    "\n",
    "# Evaluation\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Actual_Confidence': y_test,\n",
    "    'Predicted_Confidence': y_pred,\n",
    "    'Actual_Class': y_test_class,\n",
    "    'Predicted_Class': y_pred_class\n",
    "})\n",
    "print(\"\\n Top 10 Predictions vs Actuals:\")\n",
    "print(comparison_df.head(10))\n",
    "\n",
    "print(\"\\n Mean Squared Error:\", mean_squared_error(y_test, y_pred))\n",
    "print(\"\\n Classification Report:\")\n",
    "print(classification_report(y_test_class, y_pred_class))\n",
    "print(\"\\n Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test_class, y_pred_class))\n",
    "accuracy = accuracy_score(y_test_class, y_pred_class)\n",
    "print(f\"\\n Overall Accuracy: {accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a5792b-4972-4c9e-b515-e1b69be8356a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e420adf8-5698-408f-9d2f-a260103cb87c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hybrid models used to predict the Stock Market Behaviour with Exogenous variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b2b2cb12-e80e-4ee9-af6e-c5a8e17e7242",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
      "\n",
      " Top 10 Predictions vs Actuals:\n",
      "      Actual_Confidence  Predicted_Confidence Actual_Class Predicted_Class\n",
      "247            0.572501              0.622066      Neutral         Neutral\n",
      "1293           0.639770              0.639133      Neutral         Neutral\n",
      "1562           0.423568              0.515659      Neutral         Neutral\n",
      "1101           0.255415              0.540983      Bearish         Neutral\n",
      "1161           0.635864              0.583498      Neutral         Neutral\n",
      "382            0.457954              0.524266      Neutral         Neutral\n",
      "1197           0.735602              0.636637      Bullish         Neutral\n",
      "777            0.513502              0.514264      Neutral         Neutral\n",
      "643            0.585349              0.578544      Neutral         Neutral\n",
      "275            0.511786              0.537159      Neutral         Neutral\n",
      "\n",
      " Mean Squared Error: 0.0035745173089204714\n",
      "\n",
      " Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Bearish       1.00      0.50      0.67         6\n",
      "     Bullish       0.69      0.56      0.62        77\n",
      "     Neutral       0.88      0.93      0.90       283\n",
      "\n",
      "    accuracy                           0.85       366\n",
      "   macro avg       0.86      0.66      0.73       366\n",
      "weighted avg       0.84      0.85      0.84       366\n",
      "\n",
      "\n",
      " Confusion Matrix:\n",
      "[[  3   0   3]\n",
      " [  0  43  34]\n",
      " [  0  19 264]]\n",
      "\n",
      " Overall Accuracy: 84.70%\n"
     ]
    }
   ],
   "source": [
    "# MLP + XGBoost Hybrid. (Supervised Learning)\n",
    "# This hybrid model first uses an MLP (neural network) to extract hidden features.\n",
    "# Then XGBoost is used to perform the final prediction using those deep features.\n",
    "\n",
    "# Prediction of the stock market behaviour using MLP + XGBoost Hybrid Model\n",
    "\n",
    "import pandas as pd                                          # pandas are used for data operations\n",
    "from sklearn.model_selection import train_test_split         # split dataset into train and test sets\n",
    "from sklearn.preprocessing import StandardScaler             # scale features\n",
    "from sklearn.metrics import mean_squared_error, classification_report, confusion_matrix, accuracy_score\n",
    "                                                             # evaluation metrics\n",
    "from collections import Counter                              # count class frequencies\n",
    "import numpy as np\n",
    "import tensorflow as tf                                      # for MLP\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "from xgboost import XGBRegressor                             # XGBoost model for final prediction\n",
    "\n",
    "# Loading the dataset\n",
    "df = pd.read_csv(\"C:/Users/luvkh/data/Datasets/stock_data_with_exogenous_variables.csv\")\n",
    "\n",
    "# Clean column names(remove all the characters that are not letter, number or underscore)\n",
    "df.columns = df.columns.str.replace(r'[^\\w]', '_', regex=True)\n",
    "\n",
    "# These columns are used to obtain Market_Confidence hence noting it down to drop these from the training data\n",
    "formula_columns = [\n",
    "    'Price_Change', 'StockMarket_Trend', 'Sentiment',\n",
    "    'ATR', 'Stochastic', 'Momentum', 'IsFedMeetingDay', 'CoreCPI'\n",
    "]\n",
    "\n",
    "# Defining the target column\n",
    "y = df['Market_Confidence']\n",
    "\n",
    "# Defining the training column\n",
    "X = df.drop(columns=formula_columns + ['Market_Confidence'])\n",
    "\n",
    "# Selecting only numeric features (Not including Dates, Top1 - Top25, All news)\n",
    "X = X.select_dtypes(include='number')\n",
    "\n",
    "# Split into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(         # 80% data is trained, 20% is tested\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Scaling of the Training data and testing data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Fitting an MLP model for feature extraction\n",
    "input_layer = Input(shape=(X_train_scaled.shape[1],))\n",
    "x = Dense(64, activation='relu')(input_layer)\n",
    "x = Dense(32, activation='relu')(x)\n",
    "feature_model = Model(inputs=input_layer, outputs=x)\n",
    "\n",
    "feature_model.compile(optimizer='adam', loss='mse')\n",
    "feature_model.fit(X_train_scaled, y_train, epochs=50, batch_size=32, validation_split=0.1, verbose=0)\n",
    "\n",
    "# Extract deep features from MLP\n",
    "X_train_deep = feature_model.predict(X_train_scaled)\n",
    "X_test_deep = feature_model.predict(X_test_scaled)\n",
    "\n",
    "# Train XGBoost Regressor on extracted features\n",
    "xgb_model = XGBRegressor(n_estimators=100, learning_rate=0.1, max_depth=5, random_state=42)\n",
    "xgb_model.fit(X_train_deep, y_train)\n",
    "\n",
    "# Predict confidence\n",
    "y_pred = xgb_model.predict(X_test_deep)\n",
    "\n",
    "# Class assigning based upon the Market_Confidence (Bullish/Bearish/Neutral)\n",
    "def confidence_to_class(conf):\n",
    "    if conf < 0.33:\n",
    "        return \"Bearish\"\n",
    "    elif conf <= 0.66:\n",
    "        return \"Neutral\"\n",
    "    else:\n",
    "        return \"Bullish\"\n",
    "\n",
    "y_test_class = [confidence_to_class(val) for val in y_test]        # Actual class of the Market_Confidence\n",
    "y_pred_class = [confidence_to_class(val) for val in y_pred]        # Predicted class of the Market_Confidence\n",
    "\n",
    "# Creating a DataFrame consisting of 4 columns\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Actual_Confidence': y_test,\n",
    "    'Predicted_Confidence': y_pred,\n",
    "    'Actual_Class': y_test_class,\n",
    "    'Predicted_Class': y_pred_class\n",
    "})\n",
    "print(\"\\n Top 10 Predictions vs Actuals:\")\n",
    "print(comparison_df.head(10))                                      # out of the 20% tested data, it shows the top 10\n",
    "\n",
    "# Evaluation\n",
    "\n",
    "# Mean square method is used to obtain how far our model predicted from the actual values.\n",
    "# It is calculated by subtracting predicted values with actual values(error) then squaring it and taking the average.\n",
    "print(\"\\n Mean Squared Error:\", mean_squared_error(y_test, y_pred))\n",
    "\n",
    "# Classification report gives detail about how well the model handled each class\n",
    "print(\"\\n Classification Report:\")\n",
    "print(classification_report(y_test_class, y_pred_class))\n",
    "\n",
    "# A table which gives actual(rows) vs predicted(columns) value\n",
    "print(\"\\n Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test_class, y_pred_class))\n",
    "\n",
    "# Print accuracy score\n",
    "accuracy = accuracy_score(y_test_class, y_pred_class)\n",
    "print(f\"\\n Overall Accuracy: {accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2c022f41-c4ee-48be-8a48-693bbc386dcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
      "\n",
      " Top 10 Predictions vs Actuals:\n",
      "   Actual_Confidence  Predicted_Confidence Actual_Class Predicted_Class\n",
      "0           0.626303              0.899270      Neutral         Bullish\n",
      "1           0.581940              0.606801      Neutral         Neutral\n",
      "2           0.606372              0.579566      Neutral         Neutral\n",
      "3           0.568237              0.558737      Neutral         Neutral\n",
      "4           0.485682              0.582087      Neutral         Neutral\n",
      "5           0.655102              0.588408      Neutral         Neutral\n",
      "6           0.703647              0.525968      Bullish         Neutral\n",
      "7           0.612046              0.706794      Neutral         Bullish\n",
      "8           0.590268              0.648358      Neutral         Neutral\n",
      "9           0.574182              0.520569      Neutral         Neutral\n",
      "\n",
      " Mean Squared Error: 0.005648250631336995\n",
      "\n",
      " Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Bearish       0.00      0.00      0.00         4\n",
      "     Bullish       0.69      0.56      0.62        87\n",
      "     Neutral       0.86      0.92      0.89       274\n",
      "\n",
      "    accuracy                           0.82       365\n",
      "   macro avg       0.52      0.49      0.50       365\n",
      "weighted avg       0.81      0.82      0.81       365\n",
      "\n",
      "\n",
      " Confusion Matrix:\n",
      "[[  0   0   4]\n",
      " [  0  49  38]\n",
      " [  1  22 251]]\n",
      "\n",
      " Overall Accuracy: 82.19%\n"
     ]
    }
   ],
   "source": [
    "# CNN + CatBoost Hybrid. (Supervised Learning)\n",
    "# This hybrid model first uses CNN to learn local patterns in time sequences.\n",
    "# Then CatBoost is used to perform the final prediction using those CNN-based features.\n",
    "\n",
    "# Prediction of the stock market behaviour using CNN + CatBoost Hybrid Model\n",
    "\n",
    "import pandas as pd                                          # pandas are used for data operations\n",
    "from sklearn.model_selection import train_test_split         # split dataset into train and test sets\n",
    "from sklearn.preprocessing import StandardScaler             # scale features\n",
    "from sklearn.metrics import mean_squared_error, classification_report, confusion_matrix, accuracy_score\n",
    "                                                             # evaluation metrics\n",
    "from collections import Counter                              # count class frequencies\n",
    "import numpy as np\n",
    "import tensorflow as tf                                      # for CNN\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv1D, Flatten, Dense\n",
    "from catboost import CatBoostRegressor                       # CatBoost model for final prediction\n",
    "\n",
    "# Loading the dataset\n",
    "df = pd.read_csv(\"C:/Users/luvkh/data/Datasets/stock_data_with_exogenous_variables.csv\")\n",
    "\n",
    "# Clean column names(remove all the characters that are not letter, number or underscore)\n",
    "df.columns = df.columns.str.replace(r'[^\\w]', '_', regex=True)\n",
    "\n",
    "# These columns are used to obtain Market_Confidence hence noting it down to drop these from the training data\n",
    "formula_columns = [\n",
    "    'Price_Change', 'StockMarket_Trend', 'Sentiment',\n",
    "    'ATR', 'Stochastic', 'Momentum', 'IsFedMeetingDay', 'CoreCPI'\n",
    "]\n",
    "\n",
    "# Defining the target column\n",
    "y = df['Market_Confidence']\n",
    "\n",
    "# Defining the training column\n",
    "X = df.drop(columns=formula_columns + ['Market_Confidence'])\n",
    "\n",
    "# Selecting only numeric features (Not including Dates, Top1 - Top25, All news)\n",
    "X = X.select_dtypes(include='number')\n",
    "\n",
    "# Scaling of the data\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Create sequences for CNN input\n",
    "time_steps = 5\n",
    "def create_sequences(X, y, time_steps=5):\n",
    "    Xs, ys = [], []\n",
    "    for i in range(len(X) - time_steps):\n",
    "        Xs.append(X[i:i+time_steps])\n",
    "        ys.append(y[i+time_steps])\n",
    "    return np.array(Xs), np.array(ys)\n",
    "\n",
    "X_seq, y_seq = create_sequences(X_scaled, y.values, time_steps)\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_seq, y_seq, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Fix target shape to avoid shape mismatch\n",
    "y_train = y_train.reshape(-1, 1)\n",
    "y_test = y_test.reshape(-1, 1)\n",
    "\n",
    "# Fitting CNN feature extractor\n",
    "input_layer = Input(shape=(X_train.shape[1], X_train.shape[2]))\n",
    "x = Conv1D(filters=64, kernel_size=2, activation='relu')(input_layer)\n",
    "x = Flatten()(x)\n",
    "x = Dense(32, activation='relu')(x)\n",
    "cnn_model = Model(inputs=input_layer, outputs=x)\n",
    "\n",
    "cnn_model.compile(optimizer='adam', loss='mse')\n",
    "cnn_model.fit(X_train, y_train, epochs=50, batch_size=32, validation_split=0.1, verbose=0)\n",
    "\n",
    "# Extract features\n",
    "X_train_cnn = cnn_model.predict(X_train)\n",
    "X_test_cnn = cnn_model.predict(X_test)\n",
    "\n",
    "# Fit CatBoost on CNN features\n",
    "cat_model = CatBoostRegressor(verbose=0, iterations=100, learning_rate=0.1, depth=5, random_state=42)\n",
    "cat_model.fit(X_train_cnn, y_train.ravel())\n",
    "\n",
    "# Predict\n",
    "y_pred = cat_model.predict(X_test_cnn)\n",
    "\n",
    "# Class assignment based on Market_Confidence\n",
    "def confidence_to_class(conf):\n",
    "    if conf < 0.33:\n",
    "        return \"Bearish\"\n",
    "    elif conf <= 0.66:\n",
    "        return \"Neutral\"\n",
    "    else:\n",
    "        return \"Bullish\"\n",
    "\n",
    "y_test_class = [confidence_to_class(val) for val in y_test.flatten()]        # Actual class of the Market_Confidence\n",
    "y_pred_class = [confidence_to_class(val) for val in y_pred]                  # Predicted class of the Market_Confidence\n",
    "\n",
    "# Comparison DataFrame\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Actual_Confidence': y_test.flatten(),\n",
    "    'Predicted_Confidence': y_pred,\n",
    "    'Actual_Class': y_test_class,\n",
    "    'Predicted_Class': y_pred_class\n",
    "})\n",
    "print(\"\\n Top 10 Predictions vs Actuals:\")\n",
    "print(comparison_df.head(10))                                      # top 10 from test set\n",
    "\n",
    "# Evaluation\n",
    "print(\"\\n Mean Squared Error:\", mean_squared_error(y_test, y_pred))\n",
    "print(\"\\n Classification Report:\")\n",
    "print(classification_report(y_test_class, y_pred_class))\n",
    "print(\"\\n Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test_class, y_pred_class))\n",
    "accuracy = accuracy_score(y_test_class, y_pred_class)\n",
    "print(f\"\\n Overall Accuracy: {accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b0a3e25e-4102-4138-a066-abea82a3e829",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\n",
      " Top 10 Predictions vs Actuals:\n",
      "      Actual_Confidence  Predicted_Confidence Actual_Class Predicted_Class\n",
      "247            0.572501              0.571974      Neutral         Neutral\n",
      "1293           0.639770              0.608579      Neutral         Neutral\n",
      "1562           0.423568              0.651972      Neutral         Neutral\n",
      "1101           0.255415              0.568429      Bearish         Neutral\n",
      "1161           0.635864              0.669990      Neutral         Bullish\n",
      "382            0.457954              0.503044      Neutral         Neutral\n",
      "1197           0.735602              0.547747      Bullish         Neutral\n",
      "777            0.513502              0.564839      Neutral         Neutral\n",
      "643            0.585349              0.600415      Neutral         Neutral\n",
      "275            0.511786              0.556863      Neutral         Neutral\n",
      "\n",
      " Mean Squared Error: 0.008084146195288511\n",
      "\n",
      " Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Bearish       0.67      0.33      0.44         6\n",
      "     Bullish       0.36      0.13      0.19        77\n",
      "     Neutral       0.79      0.94      0.86       283\n",
      "\n",
      "    accuracy                           0.76       366\n",
      "   macro avg       0.60      0.47      0.50       366\n",
      "weighted avg       0.70      0.76      0.71       366\n",
      "\n",
      "\n",
      " Confusion Matrix:\n",
      "[[  2   0   4]\n",
      " [  1  10  66]\n",
      " [  0  18 265]]\n",
      "\n",
      " Overall Accuracy: 75.68%\n"
     ]
    }
   ],
   "source": [
    "# AutoEncoder + Random Forest Hybrid. (Supervised Learning)\n",
    "# This hybrid model first uses an AutoEncoder to compress input features and remove noise.\n",
    "# Then Random Forest is used to perform the final prediction using those compressed features.\n",
    "\n",
    "# Prediction of the stock market behaviour using AutoEncoder + Random Forest Hybrid Model\n",
    "\n",
    "import pandas as pd                                          # pandas are used for data operations\n",
    "from sklearn.model_selection import train_test_split         # used to split the data into train and test sets\n",
    "from sklearn.preprocessing import StandardScaler             # used to normalize features\n",
    "from sklearn.metrics import mean_squared_error, classification_report, confusion_matrix, accuracy_score\n",
    "                                                             # used for model evaluation\n",
    "from collections import Counter                              # used to count predicted classes\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Model                    # base class for AutoEncoder\n",
    "from tensorflow.keras.layers import Input, Dense             # layers for AutoEncoder\n",
    "from sklearn.ensemble import RandomForestRegressor           # final regressor\n",
    "\n",
    "# Loading the dataset\n",
    "df = pd.read_csv(\"C:/Users/luvkh/data/Datasets/stock_data_with_exogenous_variables.csv\")\n",
    "\n",
    "# Clean column names(remove all the characters that are not letter, number or underscore)\n",
    "df.columns = df.columns.str.replace(r'[^\\w]', '_', regex=True)\n",
    "\n",
    "# These columns are used to obtain Market_Confidence hence noting it down to drop these from the training data\n",
    "formula_columns = [\n",
    "    'Price_Change', 'StockMarket_Trend', 'Sentiment',\n",
    "    'ATR', 'Stochastic', 'Momentum', 'IsFedMeetingDay', 'CoreCPI'\n",
    "]\n",
    "\n",
    "# Defining the target column\n",
    "y = df['Market_Confidence']\n",
    "\n",
    "# Defining the training column\n",
    "X = df.drop(columns=formula_columns + ['Market_Confidence'])\n",
    "\n",
    "# Selecting only numeric features (Not including Dates, Top1 - Top25, All news)\n",
    "X = X.select_dtypes(include='number')\n",
    "\n",
    "# Split into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(         # 80% data is trained, 20% is tested\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Define AutoEncoder architecture\n",
    "input_layer = Input(shape=(X_train_scaled.shape[1],))\n",
    "encoded = Dense(32, activation='relu')(input_layer)\n",
    "encoded = Dense(16, activation='relu')(encoded)\n",
    "decoded = Dense(32, activation='relu')(encoded)\n",
    "output_layer = Dense(X_train_scaled.shape[1], activation='linear')(decoded)\n",
    "\n",
    "autoencoder = Model(inputs=input_layer, outputs=output_layer)\n",
    "encoder = Model(inputs=input_layer, outputs=encoded)  # for feature extraction\n",
    "\n",
    "autoencoder.compile(optimizer='adam', loss='mse')\n",
    "autoencoder.fit(X_train_scaled, X_train_scaled, epochs=50, batch_size=32, validation_split=0.1, verbose=0)\n",
    "\n",
    "# Extract encoded features\n",
    "X_train_encoded = encoder.predict(X_train_scaled)\n",
    "X_test_encoded = encoder.predict(X_test_scaled)\n",
    "\n",
    "# Train Random Forest on encoded features\n",
    "rf_model = RandomForestRegressor(n_estimators=100, max_depth=8, random_state=42)\n",
    "rf_model.fit(X_train_encoded, y_train)\n",
    "\n",
    "# Predict confidence\n",
    "y_pred = rf_model.predict(X_test_encoded)\n",
    "\n",
    "# Class assignment based on Market_Confidence\n",
    "def confidence_to_class(conf):\n",
    "    if conf < 0.33:\n",
    "        return \"Bearish\"\n",
    "    elif conf <= 0.66:\n",
    "        return \"Neutral\"\n",
    "    else:\n",
    "        return \"Bullish\"\n",
    "\n",
    "y_test_class = [confidence_to_class(val) for val in y_test]\n",
    "y_pred_class = [confidence_to_class(val) for val in y_pred]\n",
    "\n",
    "# Creating a DataFrame consisting of 4 columns\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Actual_Confidence': y_test,\n",
    "    'Predicted_Confidence': y_pred,\n",
    "    'Actual_Class': y_test_class,\n",
    "    'Predicted_Class': y_pred_class\n",
    "})\n",
    "print(\"\\n Top 10 Predictions vs Actuals:\")\n",
    "print(comparison_df.head(10))                                      # out of the 20% tested data, it shows the top 10\n",
    "\n",
    "# Evaluation\n",
    "\n",
    "# Mean square method is used to obtain how far our model predicted from the actual values.\n",
    "# It is calculated by subtracting predicted values with actual values(error) then squaring it and taking the average.\n",
    "print(\"\\n Mean Squared Error:\", mean_squared_error(y_test, y_pred))\n",
    "\n",
    "# Classification report gives detail about how well the model handled each class\n",
    "print(\"\\n Classification Report:\")\n",
    "print(classification_report(y_test_class, y_pred_class))\n",
    "\n",
    "# A table which gives actual(rows) vs predicted(columns) value\n",
    "print(\"\\n Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test_class, y_pred_class))\n",
    "\n",
    "# Print accuracy score\n",
    "accuracy = accuracy_score(y_test_class, y_pred_class)\n",
    "print(f\"\\n Overall Accuracy: {accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "223a3662-cb69-44fa-8e12-c0c5b66c97c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\luvkh\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n",
      "\n",
      " Mean Squared Error (shuffled): 0.0012595392324101329\n",
      "\n",
      " Classification Report (shuffled):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Bearish       0.00      0.00      0.00         2\n",
      "     Bullish       0.98      0.59      0.73        87\n",
      "     Neutral       0.88      1.00      0.93       277\n",
      "\n",
      "    accuracy                           0.89       366\n",
      "   macro avg       0.62      0.53      0.56       366\n",
      "weighted avg       0.90      0.89      0.88       366\n",
      "\n",
      "\n",
      " Confusion Matrix (shuffled):\n",
      "[[  0   0   2]\n",
      " [  0  51  36]\n",
      " [  0   1 276]]\n",
      "\n",
      " ✅ Shuffled Label Accuracy: 89.34%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\luvkh\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\luvkh\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\luvkh\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error, classification_report, confusion_matrix\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "# Load and clean dataset\n",
    "df = pd.read_csv(\"C:/Users/luvkh/data/Datasets/stock_data_with_exogenous_variables.csv\")\n",
    "df.columns = df.columns.str.replace(r'[^\\w]', '_', regex=True)\n",
    "\n",
    "# Drop formula columns\n",
    "formula_columns = [\n",
    "    'Price_Change', 'StockMarket_Trend', 'Sentiment',\n",
    "    'ATR', 'Stochastic', 'Momentum', 'IsFedMeetingDay', 'CoreCPI'\n",
    "]\n",
    "y = df['Market_Confidence']\n",
    "X = df.drop(columns=formula_columns + ['Market_Confidence'])\n",
    "X = X.select_dtypes(include='number')\n",
    "\n",
    "# Shuffle the target\n",
    "y_shuffled = np.random.permutation(y.values)\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_shuffled, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Base Model 1: Random Forest\n",
    "rf = RandomForestRegressor(n_estimators=100, max_depth=8, random_state=42)\n",
    "rf.fit(X_train_scaled, y_train)\n",
    "rf_pred = rf.predict(X_test_scaled)\n",
    "\n",
    "# Base Model 2: XGBoost\n",
    "xgb = XGBRegressor(n_estimators=100, learning_rate=0.1, max_depth=5, random_state=42)\n",
    "xgb.fit(X_train_scaled, y_train)\n",
    "xgb_pred = xgb.predict(X_test_scaled)\n",
    "\n",
    "# Base Model 3: MLP\n",
    "mlp = Sequential([\n",
    "    Dense(64, activation='relu', input_shape=(X_train_scaled.shape[1],)),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "mlp.compile(optimizer='adam', loss='mse')\n",
    "mlp.fit(X_train_scaled, y_train, epochs=50, batch_size=32, validation_split=0.1, verbose=0)\n",
    "mlp_pred = mlp.predict(X_test_scaled).flatten()\n",
    "\n",
    "# Stack base predictions\n",
    "stacked_X = np.column_stack((rf_pred, xgb_pred, mlp_pred))\n",
    "\n",
    "# Meta-learner\n",
    "meta_model = XGBRegressor(n_estimators=100, learning_rate=0.1, random_state=42)\n",
    "meta_model.fit(stacked_X, y_test)\n",
    "final_pred = meta_model.predict(stacked_X)\n",
    "\n",
    "# Convert prediction to class\n",
    "def confidence_to_class(conf):\n",
    "    if conf < 0.33:\n",
    "        return \"Bearish\"\n",
    "    elif conf <= 0.66:\n",
    "        return \"Neutral\"\n",
    "    else:\n",
    "        return \"Bullish\"\n",
    "\n",
    "y_test_class = [confidence_to_class(val) for val in y_test]\n",
    "final_pred_class = [confidence_to_class(val) for val in final_pred]\n",
    "\n",
    "# Evaluation\n",
    "print(\"\\n Mean Squared Error (shuffled):\", mean_squared_error(y_test, final_pred))\n",
    "print(\"\\n Classification Report (shuffled):\")\n",
    "print(classification_report(y_test_class, final_pred_class))\n",
    "print(\"\\n Confusion Matrix (shuffled):\")\n",
    "print(confusion_matrix(y_test_class, final_pred_class))\n",
    "accuracy = accuracy_score(y_test_class, final_pred_class)\n",
    "print(f\"\\n ✅ Shuffled Label Accuracy: {accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46916740-b06b-4cd2-bf1a-86ccfe443850",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
